{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import sklearn\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.regularizers import l1\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "\n",
    "# create session explicitly and keep a reference\n",
    "# so we can access and evaluate tensors directly \n",
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global config variables \n",
    "model_name = \"streeteye_lstm\"\n",
    "#data_file = \"lstm_dump_test.txt\"\n",
    "data_file = \"dump_2017_words.txt\"\n",
    "\n",
    "checkpoint_dir = \"/home/ubuntu/mount/Notebooks/checkpoints\"\n",
    "tensorboard_dir =\"/home/ubuntu/mount/Notebooks/tensorboard\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded data.\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "# 1. load data\n",
    "############################################################\n",
    "\n",
    "# load dataset\n",
    "print(\"Loading data...\")\n",
    "data=[]\n",
    "y=[]\n",
    "\n",
    "# count words\n",
    "c = collections.Counter()\n",
    "\n",
    "with open(data_file, \"r\") as infile:\n",
    "    for line in infile:\n",
    "        l = line.rstrip('\\n').split(\",\")\n",
    "        label = l.pop(0)\n",
    "        # skip empty headlines\n",
    "        if len(l[0]) == 0:\n",
    "            continue\n",
    "        if '' in l:\n",
    "            l = [w for w in l if w]\n",
    "        data.append(l)\n",
    "        y.append(label)\n",
    "        c.update(l)\n",
    "        \n",
    "print(\"Loaded data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['UNK', -1], ('domain_otherdomain', 119708), ('subsource_othersubsource', 47862), ('trump', 21141), ('with', 10761), ('domain_youtube.com', 8908), ('us', 8434), ('2017', 7862), ('from', 7768), ('subsource_memeorandum', 7712)]\n",
      "[('hazard', 17), ('alexei', 17), ('molly', 17), ('expel', 17), ('champ', 17), ('admiral', 17), ('conversational', 17), ('memorable', 17), ('wharton', 17), ('torn', 17)]\n"
     ]
    }
   ],
   "source": [
    "# create a list of top words        \n",
    "vocabulary_size = 10000 # set this to have ~20 for least popular\n",
    "count = [['UNK', -1]]\n",
    "count.extend(c.most_common(vocabulary_size - 1))\n",
    "print(count[:10])\n",
    "print(count[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = dict()\n",
    "# map words into a dict of ints\n",
    "for word, _ in count:\n",
    "    dictionary[word] = len(dictionary)\n",
    "\n",
    "data_embeddings=[]\n",
    "unk_count = 0\n",
    "\n",
    "for obs in data:\n",
    "    embedlist = []\n",
    "    for word in obs:\n",
    "        if word in dictionary:\n",
    "            index = dictionary[word]\n",
    "        else:\n",
    "            index = 0  # dictionary['UNK']\n",
    "            unk_count = unk_count + 1\n",
    "        embedlist.append(index)\n",
    "    data_embeddings.append(embedlist)\n",
    "        \n",
    "count[0][1] = unk_count\n",
    "reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "trump\n"
     ]
    }
   ],
   "source": [
    "print(dictionary['trump'])\n",
    "print(reverse_dictionary[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fd4e4911c90>]], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEICAYAAACj2qi6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEcdJREFUeJzt3X/MnWV9x/H3R+oYQWEg7gkBspLY/cGPiLEpZO6PM8mg\nm8tgiZo6JjVjdhls0YRkKf7DpiGBPyaLiZB1o6E4FRt/BCJzpgNPzJLxozoNFkUagUAHNFIm1gSk\n+N0fz3Xc4Wnrcz0/2sPT834lJ+c+3/u+rnOdb5RPzn3fz2mqCkmSerxh0guQJK0choYkqZuhIUnq\nZmhIkroZGpKkboaGJKmboSFJ6mZoSEdBklOTfCXJz5I8meRPJ70maTFWTXoB0pT4NPBzYAa4ALgn\nyXeratdklyUtTPyLcOnISnIi8AJwXlX9sNXuAP6nqjZPdHHSAnl6Sjryfhs4MAqM5rvAuRNaj7Ro\nhoZ05L0JeHFO7UXgzRNYi7QkhoZ05O0HTppTOxn46QTWIi2JoSEdeT8EViVZM1Z7O+BFcK04XgiX\njoIkdwIF/AXwDuAe4He8e0orjd80pKPjauAEYC/wOeCvDAytRH7TkCR185uGJKmboSFJ6mZoSJK6\nGRqSpG7H3A8WnnbaabV69eoFj/vZz37GiSeeuPwLWmHsgz0AezAyTX341re+9eOqeut8xx1zobF6\n9Wp27ty54HHD4ZDBYLD8C1ph7IM9AHswMk19SPJkz3GenpIkdTM0JEndDA1JUjdDQ5LUzdCQJHUz\nNCRJ3QwNSVI3Q0OS1M3QkCR1O+b+InypVm++ZyLv+8SN75nI+0rSQvhNQ5LUzdCQJHUzNCRJ3QwN\nSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUbd7QSHJWkm8keSTJ\nriQfafVTk+xI8lh7PmVszHVJdid5NMmlY/V3Jnm47ftUkrT68Um+0OoPJFk9NmZje4/Hkmxczg8v\nSVqYnm8aB4Brq+oc4CLgmiTnAJuBe6tqDXBve03btwE4F1gP3JLkuDbXrcCHgTXtsb7VrwJeqKq3\nATcDN7W5TgWuBy4E1gHXj4eTJOnomjc0quqZqvp22/4p8H3gDOAyYFs7bBtwedu+DLizql6uqseB\n3cC6JKcDJ1XV/VVVwB1zxozm+iJwcfsWcimwo6r2VdULwA7+P2gkSUfZgv4Rpnba6B3AA8BMVT3T\ndj0LzLTtM4D7x4Y93WqvtO259dGYpwCq6kCSnwBvGa8fYsz4ujYBmwBmZmYYDocL+VgA7N+/n+Fw\nyLXnH1jw2OWwmDUfCaM+TDN7YA9G7MPBukMjyZuALwEfraoX2+UIAKqqktQRWF+XqtoCbAFYu3Zt\nDQaDBc8xHA4ZDAZ8aFL/ct8Vg4m871yjPkwze2APRuzDwbrunkryRmYD47NV9eVWfq6dcqI97231\nPcBZY8PPbLU9bXtu/TVjkqwCTgae/xVzSZImoOfuqQC3Ad+vqk+O7bobGN3NtBG4a6y+od0RdTaz\nF7wfbKeyXkxyUZvzyjljRnO9F7ivXff4OnBJklPaBfBLWk2SNAE9p6feBXwQeDjJd1rtY8CNwPYk\nVwFPAu8HqKpdSbYDjzB759U1VfVqG3c1cDtwAvC19oDZUPpMkt3APmbvvqKq9iX5BPBQO+7jVbVv\nkZ9VkrRE84ZGVf0nkMPsvvgwY24AbjhEfSdw3iHqLwHvO8xcW4Gt861TknTk+RfhkqRuhoYkqZuh\nIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuh\nIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuh\nIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqdu8\noZFka5K9Sb43Vvu7JHuSfKc9/nBs33VJdid5NMmlY/V3Jnm47ftUkrT68Um+0OoPJFk9NmZjksfa\nY+NyfWhJ0uL0fNO4HVh/iPrNVXVBe/wbQJJzgA3AuW3MLUmOa8ffCnwYWNMeozmvAl6oqrcBNwM3\ntblOBa4HLgTWAdcnOWXBn1CStGzmDY2q+iawr3O+y4A7q+rlqnoc2A2sS3I6cFJV3V9VBdwBXD42\nZlvb/iJwcfsWcimwo6r2VdULwA4OHV6SpKNk1RLG/k2SK4GdwLXtP+xnAPePHfN0q73StufWac9P\nAVTVgSQ/Ad4yXj/EmNdIsgnYBDAzM8NwOFzwh9m/fz/D4ZBrzz+w4LHLYTFrPhJGfZhm9sAejNiH\ngy02NG4FPgFUe/4H4M+Xa1ELVVVbgC0Aa9eurcFgsOA5hsMhg8GAD22+Z5lX1+eJKwYTed+5Rn2Y\nZvbAHozYh4Mt6u6pqnquql6tql8A/8zsNQeAPcBZY4ee2Wp72vbc+mvGJFkFnAw8/yvmkiRNyKJC\no12jGPkTYHRn1d3AhnZH1NnMXvB+sKqeAV5MclG7XnElcNfYmNGdUe8F7mvXPb4OXJLklHYB/JJW\nkyRNyLynp5J8HhgApyV5mtk7mgZJLmD29NQTwF8CVNWuJNuBR4ADwDVV9Wqb6mpm78Q6AfhaewDc\nBnwmyW5mL7hvaHPtS/IJ4KF23MerqveCvCTpCJg3NKrqA4co3/Yrjr8BuOEQ9Z3AeYeovwS87zBz\nbQW2zrdGSdLR4V+ES5K6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKk\nboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKk\nboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKk\nboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSp27yhkWRrkr1JvjdWOzXJjiSPtedTxvZdl2R3kkeTXDpW\nf2eSh9u+TyVJqx+f5Aut/kCS1WNjNrb3eCzJxuX60JKkxen5pnE7sH5ObTNwb1WtAe5tr0lyDrAB\nOLeNuSXJcW3MrcCHgTXtMZrzKuCFqnobcDNwU5vrVOB64EJgHXD9eDhJko6+eUOjqr4J7JtTvgzY\n1ra3AZeP1e+sqper6nFgN7AuyenASVV1f1UVcMecMaO5vghc3L6FXArsqKp9VfUCsIODw0uSdBSt\nWuS4map6pm0/C8y07TOA+8eOe7rVXmnbc+ujMU8BVNWBJD8B3jJeP8SY10iyCdgEMDMzw3A4XPAH\n2r9/P8PhkGvPP7DgscthMWs+EkZ9mGb2wB6M2IeDLTY0fqmqKkktx2KWsIYtwBaAtWvX1mAwWPAc\nw+GQwWDAhzbfs8yr6/PEFYOJvO9coz5MM3tgD0bsw8EWe/fUc+2UE+15b6vvAc4aO+7MVtvTtufW\nXzMmySrgZOD5XzGXJGlCFhsadwOju5k2AneN1Te0O6LOZvaC94PtVNaLSS5q1yuunDNmNNd7gfva\ndY+vA5ckOaVdAL+k1SRJEzLv6akknwcGwGlJnmb2jqYbge1JrgKeBN4PUFW7kmwHHgEOANdU1att\nqquZvRPrBOBr7QFwG/CZJLuZveC+oc21L8kngIfacR+vqrkX5CVJR9G8oVFVHzjMrosPc/wNwA2H\nqO8EzjtE/SXgfYeZayuwdb41SpKODv8iXJLUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0M\nDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0M\nDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0M\nDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHVbUmgkeSLJw0m+k2Rnq52aZEeSx9rzKWPH\nX5dkd5JHk1w6Vn9nm2d3kk8lSasfn+QLrf5AktVLWa8kaWmW45vG71XVBVW1tr3eDNxbVWuAe9tr\nkpwDbADOBdYDtyQ5ro25FfgwsKY91rf6VcALVfU24GbgpmVYryRpkY7E6anLgG1textw+Vj9zqp6\nuaoeB3YD65KcDpxUVfdXVQF3zBkzmuuLwMWjbyGSpKNv1RLHF/AfSV4F/qmqtgAzVfVM2/8sMNO2\nzwDuHxv7dKu90rbn1kdjngKoqgNJfgK8Bfjx+CKSbAI2AczMzDAcDhf8Qfbv389wOOTa8w8seOxy\nWMyaj4RRH6aZPbAHI/bhYEsNjd+tqj1JfhPYkeQH4zurqpLUEt9jXi2stgCsXbu2BoPBgucYDocM\nBgM+tPmeZV5dnyeuGEzkfeca9WGa2QN7MGIfDrak01NVtac97wW+AqwDnmunnGjPe9vhe4Czxoaf\n2Wp72vbc+mvGJFkFnAw8v5Q1S5IWb9GhkeTEJG8ebQOXAN8D7gY2tsM2Ane17buBDe2OqLOZveD9\nYDuV9WKSi9r1iivnjBnN9V7gvnbdQ5I0AUs5PTUDfKVdl14FfK6q/j3JQ8D2JFcBTwLvB6iqXUm2\nA48AB4BrqurVNtfVwO3ACcDX2gPgNuAzSXYD+5i9+0qSNCGLDo2q+hHw9kPUnwcuPsyYG4AbDlHf\nCZx3iPpLwPsWu0ZJ0vLyL8IlSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ\n3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ\n3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ\n3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktRtRYRGkvVJHk2yO8nmSa9HkqbV6z40khwHfBr4\nA+Ac4ANJzpnsqiRpOq2a9AI6rAN2V9WPAJLcCVwGPDLRVS2z1Zvvmdh7P3Hjeyb23pJWlpUQGmcA\nT429fhq4cPyAJJuATe3l/iSPLuJ9TgN+vKgVrnC56TUvp7YPY+yBPRiZpj78Vs9BKyE05lVVW4At\nS5kjyc6qWrtMS1qx7IM9AHswYh8O9rq/pgHsAc4ae31mq0mSjrKVEBoPAWuSnJ3k14ANwN0TXpMk\nTaXX/empqjqQ5K+BrwPHAVuratcReKslnd46htgHewD2YMQ+zJGqmvQaJEkrxEo4PSVJep0wNCRJ\n3QwNpudnSpJsTbI3yffGaqcm2ZHksfZ8yti+61pPHk1y6WRWvbySnJXkG0keSbIryUdafWr6kOTX\nkzyY5LutB3/f6lPTg5EkxyX57yRfba+nrgcLNfWhMWU/U3I7sH5ObTNwb1WtAe5tr2k92ACc28bc\n0nq10h0Arq2qc4CLgGvaZ52mPrwMvLuq3g5cAKxPchHT1YORjwDfH3s9jT1YkKkPDcZ+pqSqfg6M\nfqbkmFNV3wT2zSlfBmxr29uAy8fqd1bVy1X1OLCb2V6taFX1TFV9u23/lNn/YJzBFPWhZu1vL9/Y\nHsUU9QAgyZnAe4B/GStPVQ8Ww9A49M+UnDGhtUzCTFU907afBWba9jHflySrgXcADzBlfWinZb4D\n7AV2VNXU9QD4R+BvgV+M1aatBwtmaOiXavb+66m4BzvJm4AvAR+tqhfH901DH6rq1aq6gNlfWFiX\n5Lw5+4/pHiT5I2BvVX3rcMcc6z1YLEPDnyl5LsnpAO15b6sfs31J8kZmA+OzVfXlVp66PgBU1f8C\n32D2PP009eBdwB8neYLZU9LvTvKvTFcPFsXQ8GdK7gY2tu2NwF1j9Q1Jjk9yNrAGeHAC61tWSQLc\nBny/qj45tmtq+pDkrUl+o22fAPw+8AOmqAdVdV1VnVlVq5n9//x9VfVnTFEPFut1/zMiR9pR/JmS\niUvyeWAAnJbkaeB64EZge5KrgCeB9wNU1a4k25n9d0sOANdU1asTWfjyehfwQeDhdk4f4GNMVx9O\nB7a1u3/eAGyvqq8m+S+mpweHM03/O1gUf0ZEktTN01OSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYk\nqZuhIUnq9n9K8+wLvazDjAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd4e4911450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ls = (map(len, data_embeddings))\n",
    "pd.DataFrame(ls).hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218419, 120)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LENGTH = 120\n",
    "X = sequence.pad_sequences(data_embeddings, maxlen=MAX_LENGTH)\n",
    "X[0]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(218419, 1)\n",
      "Observations: 218419\n",
      "Features: 120\n",
      "Split into training, temp\n",
      "Split into xval, test\n"
     ]
    }
   ],
   "source": [
    "y=np.array(np.float32(y))\n",
    "\n",
    "y=y.reshape((y.shape[0],1))\n",
    "print(y.shape)\n",
    "num_labels=1\n",
    "\n",
    "num_obs, num_features = X.shape\n",
    "print(\"Observations: %d\\nFeatures: %d\" % (num_obs, num_features))\n",
    "\n",
    "# split into training, xval, test, 60/20/20\n",
    "print(\"Split into training, temp\")\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4)\n",
    "print(\"Split into xval, test\")\n",
    "X_xval, X_test, y_xval, y_test = train_test_split(X_temp, y_temp, test_size=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set\n",
      "(131051, 120)\n",
      "Xval set\n",
      "(43684, 120)\n",
      "Test set\n",
      "(43684, 120)\n",
      "\n",
      "Training observations:  131051  \n",
      "Xval observations:  43684  \n",
      "Test observations:  43684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Training set\")\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"Xval set\")\n",
    "print(X_xval.shape)\n",
    "\n",
    "print(\"Test set\")\n",
    "print(X_test.shape)\n",
    "\n",
    "num_training_samples = X_train.shape[0]\n",
    "num_xval_samples = X_xval.shape[0]\n",
    "num_test_samples = X_test.shape[0]\n",
    "\n",
    "print (\"\\nTraining observations:  %d  \\nXval observations:  %d  \\nTest observations:  %d\\n\" % (num_training_samples, num_xval_samples, num_test_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize embeddings to pre-trained vals\n",
    "pkl_file = open('embeddings.pkl', 'rb')\n",
    "embeddings_dict, embeddings_reverse_dict, embeddings_data = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized 10000 embeddings\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM=300\n",
    "\n",
    "# +1 seems like an off-by-one somewhere\n",
    "embedding_matrix = np.zeros((len(dictionary) + 1, EMBEDDING_DIM))\n",
    "\n",
    "count = 0\n",
    "for word, i in dictionary.items():\n",
    "    #print(word)\n",
    "    embed_i = embeddings_dict.get(word)\n",
    "    if embed_i is not None:\n",
    "        embedding_vector = embeddings_data[i]\n",
    "        count +=1\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "print(\"initialized %d embeddings\" % count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define some custom metrics\n",
    "import keras.backend as K\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    # return keras tensor for recall\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    # return keras tensor for precision\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "\n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "def f_score(y_true, y_pred):\n",
    "    beta = 1 #  can adjust to penalize false positives/negatives\n",
    "    return fbeta_score(y_true, y_pred, beta=beta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to generate model\n",
    "\n",
    "def create_model(lstm_size=30, lstm_reg_penalty=0.0, sigmoid_dropout=(1.0/3.0), sigmoid_reg_penalty=0.0001, train_embed=True):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Embedding(len(dictionary) + 1, \n",
    "                        embedding_vector_length, \n",
    "                        weights=[embedding_matrix],\n",
    "                        input_length=MAX_LENGTH,\n",
    "                        trainable=train_embed))\n",
    "    \n",
    "    # LSTM with lstm_size units\n",
    "    model.add(LSTM(lstm_size,\n",
    "                   kernel_regularizer=l1(lstm_reg_penalty)))\n",
    "    model.add(Dropout(sigmoid_dropout))\n",
    "    \n",
    "    model.add(Dense(1, \n",
    "                    activation='sigmoid',\n",
    "                    kernel_initializer='TruncatedNormal', \n",
    "                    kernel_regularizer=l1(sigmoid_reg_penalty)))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', f_score])\n",
    "    print(model.summary())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def selectThreshold (logits, labels, beta=(2.0/3)):\n",
    "    # return threshold, f-score that yields best F-score\n",
    "    # predict using true if >= threshold\n",
    "\n",
    "    precision, recall, thresholds = sklearn.metrics.precision_recall_curve(labels, logits)\n",
    "    bb = beta**2\n",
    "    f1_scores = (1 + bb) * precision * recall / (bb * precision + recall)\n",
    "    f1_scores = np.nan_to_num(f1_scores)\n",
    "    \n",
    "    best_index = np.argmax(f1_scores)\n",
    "    best_threshold = thresholds[best_index]\n",
    "    best_score = f1_scores[best_index]\n",
    "    return (best_threshold, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 16)                20288     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,020,605.0\n",
      "Trainable params: 3,020,605.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "13:49:47 Starting (unfrozen)...\n",
      "LSTM units 16\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 313s - loss: 0.3298 - acc: 0.9659 - val_loss: 0.1507 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 312s - loss: 0.1398 - acc: 0.9726 - val_loss: 0.1333 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 202s - loss: 0.1309 - acc: 0.9726 - val_loss: 0.1317 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 163s - loss: 0.1206 - acc: 0.9726 - val_loss: 0.0806 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 163s - loss: 0.0647 - acc: 0.9827 - val_loss: 0.0554 - val_acc: 0.9842\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 163s - loss: 0.0470 - acc: 0.9878 - val_loss: 0.0516 - val_acc: 0.9842\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 163s - loss: 0.0360 - acc: 0.9912 - val_loss: 0.0555 - val_acc: 0.9837\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 163s - loss: 0.0282 - acc: 0.9937 - val_loss: 0.0594 - val_acc: 0.9826\n",
      "14:17:15 Best Xval loss epoch 5, value 0.051646\n",
      "14:17:15 Using epoch 4, value 0.051646\n",
      "14:17:15 Finished (unfrozen)...\n",
      "LSTM units 16\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "14:18:34 Train Accuracy 0.996, Train F1 0.929, f_score 0.939 (beta 0.667)\n",
      "[[127310    349]\n",
      " [   150   3242]]\n",
      "14:19:00 Xval Accuracy 0.983, Xval F1 0.676, f_score 0.708 (beta 0.667)\n",
      "[[42175   503]\n",
      " [  236   770]]\n",
      "Raw score 2 0.012224\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 16)                20288     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,020,605.0\n",
      "Trainable params: 20,305.0\n",
      "Non-trainable params: 3,000,300.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "14:19:00 Continuing (frozen)...\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 130s - loss: 0.0202 - acc: 0.9959 - val_loss: 0.0725 - val_acc: 0.9826\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 129s - loss: 0.0188 - acc: 0.9960 - val_loss: 0.0762 - val_acc: 0.9828\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 129s - loss: 0.0186 - acc: 0.9962 - val_loss: 0.0749 - val_acc: 0.9823\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 129s - loss: 0.0180 - acc: 0.9962 - val_loss: 0.0780 - val_acc: 0.9823\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 129s - loss: 0.0181 - acc: 0.9964 - val_loss: 0.0788 - val_acc: 0.9825\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 129s - loss: 0.0175 - acc: 0.9965 - val_loss: 0.0792 - val_acc: 0.9822\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 129s - loss: 0.0174 - acc: 0.9966 - val_loss: 0.0785 - val_acc: 0.9828\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 129s - loss: 0.0173 - acc: 0.9966 - val_loss: 0.0807 - val_acc: 0.9820\n",
      "14:36:21 Best Xval loss epoch 0, value 0.072485\n",
      "14:36:21 Finished (frozen)...\n",
      "LSTM units 16\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "14:37:39 Train Accuracy 0.997, Train F1 0.937, f_score 0.952 (beta 0.667)\n",
      "[[127380    352]\n",
      " [    80   3239]]\n",
      "14:38:06 Xval Accuracy 0.982, Xval F1 0.673, f_score 0.693 (beta 0.667)\n",
      "[[42117   479]\n",
      " [  294   794]]\n",
      "Raw score 2 0.011446\n",
      "14:38:06 Saving...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                42624     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,042,957.0\n",
      "Trainable params: 3,042,957.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "14:38:07 Starting (unfrozen)...\n",
      "LSTM units 32\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 272s - loss: 0.2356 - acc: 0.9684 - val_loss: 0.1317 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 270s - loss: 0.1269 - acc: 0.9726 - val_loss: 0.1288 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 271s - loss: 0.1077 - acc: 0.9726 - val_loss: 0.0917 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 270s - loss: 0.0595 - acc: 0.9789 - val_loss: 0.0520 - val_acc: 0.9834\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 270s - loss: 0.0396 - acc: 0.9879 - val_loss: 0.0514 - val_acc: 0.9836\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 271s - loss: 0.0300 - acc: 0.9913 - val_loss: 0.0575 - val_acc: 0.9828\n",
      "15:05:15 Best Xval loss epoch 4, value 0.051395\n",
      "15:05:15 Using epoch 3, value 0.051395\n",
      "15:05:15 Finished (unfrozen)...\n",
      "LSTM units 32\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "15:07:02 Train Accuracy 0.995, Train F1 0.905, f_score 0.912 (beta 0.667)\n",
      "[[127195    402]\n",
      " [   265   3189]]\n",
      "15:07:37 Xval Accuracy 0.983, Xval F1 0.680, f_score 0.706 (beta 0.667)\n",
      "[[42153   485]\n",
      " [  258   788]]\n",
      "Raw score 2 0.012133\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                42624     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,042,957.0\n",
      "Trainable params: 42,657.0\n",
      "Non-trainable params: 3,000,300.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "15:07:38 Continuing (frozen)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 226s - loss: 0.0202 - acc: 0.9949 - val_loss: 0.0669 - val_acc: 0.9807\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 226s - loss: 0.0185 - acc: 0.9952 - val_loss: 0.0722 - val_acc: 0.9816\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 225s - loss: 0.0177 - acc: 0.9954 - val_loss: 0.0775 - val_acc: 0.9814\n",
      "15:18:58 Best Xval loss epoch 0, value 0.066860\n",
      "15:18:58 Finished (frozen)...\n",
      "LSTM units 32\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "15:20:46 Train Accuracy 0.996, Train F1 0.918, f_score 0.929 (beta 0.667)\n",
      "[[127278    390]\n",
      " [   182   3201]]\n",
      "15:21:22 Xval Accuracy 0.982, Xval F1 0.651, f_score 0.677 (beta 0.667)\n",
      "[[42123   519]\n",
      " [  288   754]]\n",
      "Raw score 2 0.010668\n",
      "15:21:22 Saving...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,093,805.0\n",
      "Trainable params: 3,093,805.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "15:21:23 Starting (unfrozen)...\n",
      "LSTM units 64\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 498s - loss: 0.1825 - acc: 0.9675 - val_loss: 0.1175 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 498s - loss: 0.0907 - acc: 0.9726 - val_loss: 0.0696 - val_acc: 0.9710\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 496s - loss: 0.0489 - acc: 0.9824 - val_loss: 0.0542 - val_acc: 0.9841\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 498s - loss: 0.0349 - acc: 0.9889 - val_loss: 0.0549 - val_acc: 0.9840\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 496s - loss: 0.0264 - acc: 0.9923 - val_loss: 0.0574 - val_acc: 0.9812\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 499s - loss: 0.0208 - acc: 0.9942 - val_loss: 0.0664 - val_acc: 0.9819\n",
      "16:11:12 Best Xval loss epoch 2, value 0.054193\n",
      "16:11:12 Using epoch 1, value 0.054193\n",
      "16:11:12 Finished (unfrozen)...\n",
      "LSTM units 64\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "16:14:07 Train Accuracy 0.996, Train F1 0.930, f_score 0.937 (beta 0.667)\n",
      "[[127277    309]\n",
      " [   183   3282]]\n",
      "16:15:05 Xval Accuracy 0.982, Xval F1 0.675, f_score 0.695 (beta 0.667)\n",
      "[[42111   471]\n",
      " [  300   802]]\n",
      "Raw score 2 0.011492\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,093,805.0\n",
      "Trainable params: 93,505.0\n",
      "Non-trainable params: 3,000,300.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "16:15:05 Continuing (frozen)...\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 424s - loss: 0.0141 - acc: 0.9963 - val_loss: 0.0840 - val_acc: 0.9826\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 426s - loss: 0.0129 - acc: 0.9966 - val_loss: 0.0866 - val_acc: 0.9821\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 425s - loss: 0.0118 - acc: 0.9969 - val_loss: 0.0961 - val_acc: 0.9817\n",
      "16:36:23 Best Xval loss epoch 0, value 0.084031\n",
      "16:36:23 Finished (frozen)...\n",
      "LSTM units 64\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "16:39:18 Train Accuracy 0.997, Train F1 0.947, f_score 0.952 (beta 0.667)\n",
      "[[127313    226]\n",
      " [   147   3365]]\n",
      "16:40:17 Xval Accuracy 0.982, Xval F1 0.660, f_score 0.686 (beta 0.667)\n",
      "[[42128   506]\n",
      " [  283   767]]\n",
      "Raw score 2 0.011080\n",
      "16:40:17 Saving...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,220,077.0\n",
      "Trainable params: 3,220,077.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "16:40:19 Starting (unfrozen)...\n",
      "LSTM units 128\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 1035s - loss: 0.1561 - acc: 0.9705 - val_loss: 0.1287 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 1036s - loss: 0.0938 - acc: 0.9740 - val_loss: 0.0528 - val_acc: 0.9813\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 1034s - loss: 0.0413 - acc: 0.9864 - val_loss: 0.0487 - val_acc: 0.9843\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 1034s - loss: 0.0308 - acc: 0.9901 - val_loss: 0.0542 - val_acc: 0.9829\n",
      "17:49:22 Best Xval loss epoch 2, value 0.048697\n",
      "17:49:22 Using epoch 1, value 0.048697\n",
      "17:49:22 Finished (unfrozen)...\n",
      "LSTM units 128\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "17:54:55 Train Accuracy 0.994, Train F1 0.891, f_score 0.901 (beta 0.667)\n",
      "[[127178    480]\n",
      " [   282   3111]]\n",
      "17:56:46 Xval Accuracy 0.983, Xval F1 0.678, f_score 0.709 (beta 0.667)\n",
      "[[42173   498]\n",
      " [  238   775]]\n",
      "Raw score 2 0.012293\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,220,077.0\n",
      "Trainable params: 219,777.0\n",
      "Non-trainable params: 3,000,300.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17:56:46 Continuing (frozen)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 909s - loss: 0.0211 - acc: 0.9943 - val_loss: 0.0673 - val_acc: 0.9821\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 907s - loss: 0.0200 - acc: 0.9944 - val_loss: 0.0689 - val_acc: 0.9818\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 909s - loss: 0.0189 - acc: 0.9948 - val_loss: 0.0752 - val_acc: 0.9820\n",
      "18:42:14 Best Xval loss epoch 0, value 0.067327\n",
      "18:42:14 Finished (frozen)...\n",
      "LSTM units 128\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "18:47:47 Train Accuracy 0.995, Train F1 0.909, f_score 0.921 (beta 0.667)\n",
      "[[127260    431]\n",
      " [   200   3160]]\n",
      "18:49:38 Xval Accuracy 0.982, Xval F1 0.664, f_score 0.689 (beta 0.667)\n",
      "[[42132   502]\n",
      " [  279   771]]\n",
      "Raw score 2 0.011263\n",
      "18:49:38 Saving...\n"
     ]
    }
   ],
   "source": [
    "# grid search - first train end-to-end, then freeze embeddings\n",
    "embedding_vector_length = EMBEDDING_DIM\n",
    "\n",
    "for sig_reg_penalty in [0.00003]:\n",
    "    for dropout in [0.333]:\n",
    "        for lstm_units in [16, 32, 64, 128]:\n",
    "            for lstm_reg_penalty in [0.00000,]:\n",
    "                #0.000001, 0.000003, 0.00001, 0.00003]:\n",
    "                models = []\n",
    "                xval_losses = []\n",
    "\n",
    "                model = create_model(lstm_size=lstm_units, \n",
    "                                     lstm_reg_penalty=lstm_reg_penalty, \n",
    "                                     sigmoid_dropout=dropout, \n",
    "                                     sigmoid_reg_penalty=sig_reg_penalty)\n",
    "                print('%s Starting (unfrozen)...' % time.strftime(\"%H:%M:%S\"))\n",
    "                print (\"LSTM units %d\" % lstm_units)\n",
    "                print (\"LSTM reg_penalty %.8f\" % lstm_reg_penalty)\n",
    "                print (\"Sigmoid dropout %.4f\" %  dropout)\n",
    "                print (\"Sigmoid reg_penalty %.8f\" % sig_reg_penalty)\n",
    "\n",
    "                ##################################################################\n",
    "                # train end-to-end including embeddings until xval loss bottoms out\n",
    "                ##################################################################\n",
    "                \n",
    "                epochs = 10\n",
    "                for _ in range(epochs):\n",
    "                    fit = model.fit(X_train, y_train, validation_data=(X_xval, y_xval), epochs=1, batch_size=1024)\n",
    "                    # save loss\n",
    "                    train_loss = fit.history['loss'][-1]\n",
    "                    train_acc = fit.history['acc'][-1]\n",
    "                    xval_loss = fit.history['val_loss'][-1]\n",
    "                    xval_acc = fit.history['val_acc'][-1]\n",
    "                    xval_losses.append(xval_loss)\n",
    "                    models.append(copy.copy(model))\n",
    "\n",
    "                    bestloss_index = np.argmin(xval_losses)\n",
    "                    bestloss_value = xval_losses[bestloss_index]\n",
    "\n",
    "                    # break if loss rises by 10% from best\n",
    "                    if xval_loss / bestloss_value > 1.1:\n",
    "                        break\n",
    "                    \n",
    "                # keep model from epoch with best xval loss\n",
    "                print (\"%s Best Xval loss epoch %d, value %f\" % (time.strftime(\"%H:%M:%S\"), bestloss_index, bestloss_value))\n",
    "                # go back one from best... best is usually already overfitted with .9 train f1\n",
    "                if bestloss_index > 0:\n",
    "                    bestloss_index -= 1\n",
    "                    print (\"%s Using epoch %d, value %f\" % (time.strftime(\"%H:%M:%S\"), bestloss_index, bestloss_value))\n",
    "                \n",
    "                model = models[bestloss_index]\n",
    "\n",
    "                print('%s Finished (unfrozen)...' % time.strftime(\"%H:%M:%S\"))\n",
    "                print (\"LSTM units %d\" % lstm_units)\n",
    "                print (\"LSTM reg_penalty %.8f\" % lstm_reg_penalty)\n",
    "                print (\"Sigmoid dropout %.4f\" %  dropout)\n",
    "                print (\"Sigmoid reg_penalty %.8f\" % sig_reg_penalty)                \n",
    "                \n",
    "                y_train_prob = model.predict(X_train)\n",
    "                \n",
    "                beta=(2.0/3.0) # penalize false positives more than false negatives\n",
    "                thresh, score = selectThreshold(y_train_prob, y_train, beta=beta)\n",
    "                y_train_pred = y_train_prob >= thresh\n",
    "\n",
    "                \n",
    "                print(\"%s Train Accuracy %.3f, Train F1 %.3f, f_score %.3f (beta %.3f)\" % \n",
    "                      (time.strftime(\"%H:%M:%S\"),\n",
    "                       sklearn.metrics.accuracy_score(y_train_pred, y_train), \n",
    "                       sklearn.metrics.f1_score(y_train_pred, y_train),\n",
    "                       score, beta))\n",
    "                \n",
    "                print(sklearn.metrics.confusion_matrix(y_train_pred, y_train))\n",
    "\n",
    "                y_xval_prob = model.predict(X_xval)\n",
    "                \n",
    "                thresh, score = selectThreshold(y_xval_prob, y_xval, beta=beta)\n",
    "                y_xval_pred = y_xval_prob >= thresh\n",
    "                \n",
    "                print(\"%s Xval Accuracy %.3f, Xval F1 %.3f, f_score %.3f (beta %.3f)\" % \n",
    "                      (time.strftime(\"%H:%M:%S\"),\n",
    "                       sklearn.metrics.accuracy_score(y_xval_pred, y_xval), \n",
    "                       sklearn.metrics.f1_score(y_xval_pred, y_xval),\n",
    "                       score, beta))\n",
    "                \n",
    "                confusion_matrix = sklearn.metrics.confusion_matrix(y_xval_pred, y_xval)\n",
    "                print(confusion_matrix)\n",
    "                false_positive = confusion_matrix[1][0]\n",
    "                false_negative = confusion_matrix[0][1]\n",
    "                true_positive = confusion_matrix[1][1]\n",
    "                raw_score = 1.0 * (true_positive - false_positive) / np.sum(confusion_matrix)\n",
    "                print (\"Raw score 2 %f\" % raw_score)\n",
    "\n",
    "                ##################################################################\n",
    "                # freeze embeddings, train LSTM until xval loss bottoms out\n",
    "                ##################################################################\n",
    "                elayer = model.layers[0]\n",
    "                \n",
    "                elayer.trainable = False\n",
    "                model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "                print(model.summary())\n",
    "\n",
    "                # Could also keep existing list of models in case further training makes it worse                \n",
    "                models = []\n",
    "                xval_losses = []\n",
    "                epochs = 20\n",
    "\n",
    "                print('%s Continuing (frozen)...' % time.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "                for _ in range(epochs):\n",
    "                    fit = model.fit(X_train, y_train, validation_data=(X_xval, y_xval), epochs=1, batch_size=1024)\n",
    "                    # save losses\n",
    "                    train_loss = fit.history['loss'][-1]\n",
    "                    train_acc = fit.history['acc'][-1]\n",
    "                    xval_loss = fit.history['val_loss'][-1]\n",
    "                    xval_acc = fit.history['val_acc'][-1]\n",
    "                    xval_losses.append(xval_loss)\n",
    "                    models.append(copy.copy(model))\n",
    "\n",
    "                    bestloss_index = np.argmin(xval_losses)\n",
    "                    bestloss_value = xval_losses[bestloss_index]\n",
    "    \n",
    "                    # break if loss rises by 10% from best\n",
    "                    if xval_loss / bestloss_value > 1.1:\n",
    "                        break\n",
    "                    \n",
    "                # keep model from epoch with best xval loss\n",
    "                print (\"%s Best Xval loss epoch %d, value %f\" % (time.strftime(\"%H:%M:%S\"), bestloss_index, bestloss_value))\n",
    "                model = models[bestloss_index]\n",
    "\n",
    "                print('%s Finished (frozen)...' % time.strftime(\"%H:%M:%S\"))\n",
    "                print (\"LSTM units %d\" % lstm_units)\n",
    "                print (\"LSTM reg_penalty %.8f\" % lstm_reg_penalty)\n",
    "                print (\"Sigmoid dropout %.4f\" %  dropout)\n",
    "                print (\"Sigmoid reg_penalty %.8f\" % sig_reg_penalty)                \n",
    "               \n",
    "                y_train_prob = model.predict(X_train)\n",
    "                \n",
    "                beta=(2.0/3.0) # penalize false positives more than false negatives\n",
    "                thresh, score = selectThreshold(y_train_prob, y_train, beta=beta)\n",
    "                y_train_pred = y_train_prob >= thresh\n",
    "                \n",
    "                print(\"%s Train Accuracy %.3f, Train F1 %.3f, f_score %.3f (beta %.3f)\" % \n",
    "                      (time.strftime(\"%H:%M:%S\"),\n",
    "                       sklearn.metrics.accuracy_score(y_train_pred, y_train),\n",
    "                       sklearn.metrics.f1_score(y_train_pred, y_train),\n",
    "                       score, beta))\n",
    "                \n",
    "                print(sklearn.metrics.confusion_matrix(y_train_pred, y_train))\n",
    "\n",
    "                y_xval_prob = model.predict(X_xval)\n",
    "                \n",
    "                thresh, score = selectThreshold(y_xval_prob, y_xval, beta=beta)\n",
    "                y_xval_pred = y_xval_prob >= thresh\n",
    "\n",
    "                print(\"%s Xval Accuracy %.3f, Xval F1 %.3f, f_score %.3f (beta %.3f)\" % \n",
    "                      (time.strftime(\"%H:%M:%S\"),\n",
    "                       sklearn.metrics.accuracy_score(y_xval_pred, y_xval), \n",
    "                       sklearn.metrics.f1_score(y_xval_pred, y_xval),\n",
    "                       score, beta))\n",
    "                \n",
    "                confusion_matrix = sklearn.metrics.confusion_matrix(y_xval_pred, y_xval)\n",
    "                print(confusion_matrix)\n",
    "                false_positive = confusion_matrix[1][0]\n",
    "                false_negative = confusion_matrix[0][1]\n",
    "                true_positive = confusion_matrix[1][1]\n",
    "\n",
    "                raw_score = 1.0 * (true_positive - false_positive) / np.sum(confusion_matrix)\n",
    "                print (\"Raw score 2 %f\" % raw_score)\n",
    "                \n",
    "                # save model to disk\n",
    "                print('%s Saving...' % time.strftime(\"%H:%M:%S\"))               \n",
    "                modelname = \"model_%d_%.6f_%.3f_%.6f\" % (lstm_units, lstm_reg_penalty, dropout, sig_reg_penalty)\n",
    "                model.save(\"%s.h5\" % modelname)\n",
    "                model.save_weights(\"%s_weights.h5\" % modelname)\n",
    "                with open(\"%s.json\" % modelname, \"wb\") as fjson:\n",
    "                    fjson.write(model.to_json()) \n",
    "                    \n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 16)                20288     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,020,605.0\n",
      "Trainable params: 3,020,605.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "18:49:40 Starting (unfrozen)...\n",
      "LSTM units 16\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 165s - loss: 0.3365 - acc: 0.9710 - val_loss: 0.1555 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 164s - loss: 0.1420 - acc: 0.9726 - val_loss: 0.1340 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 164s - loss: 0.1313 - acc: 0.9726 - val_loss: 0.1292 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 164s - loss: 0.0903 - acc: 0.9775 - val_loss: 0.0616 - val_acc: 0.9838\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 163s - loss: 0.0551 - acc: 0.9863 - val_loss: 0.0537 - val_acc: 0.9850\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 163s - loss: 0.0410 - acc: 0.9904 - val_loss: 0.0548 - val_acc: 0.9838\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 163s - loss: 0.0320 - acc: 0.9931 - val_loss: 0.0591 - val_acc: 0.9824\n",
      "19:08:51 Best Xval loss epoch 4, value 0.053651\n",
      "19:08:51 Finished (unfrozen)...\n",
      "LSTM units 16\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "19:10:10 Train Accuracy 0.996, Train F1 0.920, f_score 0.930 (beta 0.667)\n",
      "[[127276    376]\n",
      " [   184   3215]]\n",
      "19:10:36 Xval Accuracy 0.983, Xval F1 0.654, f_score 0.700 (beta 0.667)\n",
      "[[42221   562]\n",
      " [  190   711]]\n",
      "Raw score 2 0.011927\n",
      "19:10:37 Saving...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 32)                42624     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,042,957.0\n",
      "Trainable params: 3,042,957.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "19:10:39 Starting (unfrozen)...\n",
      "LSTM units 32\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 273s - loss: 0.2397 - acc: 0.9659 - val_loss: 0.1316 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 272s - loss: 0.1265 - acc: 0.9726 - val_loss: 0.1282 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 273s - loss: 0.0893 - acc: 0.9740 - val_loss: 0.0597 - val_acc: 0.9815\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 273s - loss: 0.0480 - acc: 0.9854 - val_loss: 0.0519 - val_acc: 0.9842\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 272s - loss: 0.0362 - acc: 0.9895 - val_loss: 0.0501 - val_acc: 0.9836\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 273s - loss: 0.0278 - acc: 0.9925 - val_loss: 0.0539 - val_acc: 0.9829\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 273s - loss: 0.0217 - acc: 0.9947 - val_loss: 0.0614 - val_acc: 0.9823\n",
      "19:42:33 Best Xval loss epoch 4, value 0.050094\n",
      "19:42:33 Finished (unfrozen)...\n",
      "LSTM units 32\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "19:44:22 Train Accuracy 0.997, Train F1 0.936, f_score 0.947 (beta 0.667)\n",
      "[[127344    333]\n",
      " [   116   3258]]\n",
      "19:44:58 Xval Accuracy 0.982, Xval F1 0.680, f_score 0.696 (beta 0.667)\n",
      "[[42101   458]\n",
      " [  310   815]]\n",
      "Raw score 2 0.011560\n",
      "19:44:58 Saving...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,093,805.0\n",
      "Trainable params: 3,093,805.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "19:45:01 Starting (unfrozen)...\n",
      "LSTM units 64\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 511s - loss: 0.1869 - acc: 0.9686 - val_loss: 0.1309 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 513s - loss: 0.1211 - acc: 0.9726 - val_loss: 0.1197 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 513s - loss: 0.0943 - acc: 0.9726 - val_loss: 0.0859 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 513s - loss: 0.0495 - acc: 0.9823 - val_loss: 0.0559 - val_acc: 0.9840\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 512s - loss: 0.0339 - acc: 0.9896 - val_loss: 0.0555 - val_acc: 0.9822\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 513s - loss: 0.0260 - acc: 0.9925 - val_loss: 0.0617 - val_acc: 0.9816\n",
      "20:36:19 Best Xval loss epoch 4, value 0.055506\n",
      "20:36:19 Finished (unfrozen)...\n",
      "LSTM units 64\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "20:39:16 Train Accuracy 0.995, Train F1 0.914, f_score 0.923 (beta 0.667)\n",
      "[[127249    391]\n",
      " [   211   3200]]\n",
      "20:40:15 Xval Accuracy 0.982, Xval F1 0.635, f_score 0.683 (beta 0.667)\n",
      "[[42213   588]\n",
      " [  198   685]]\n",
      "Raw score 2 0.011148\n",
      "20:40:15 Saving...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,220,077.0\n",
      "Trainable params: 3,220,077.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "20:40:17 Starting (unfrozen)...\n",
      "LSTM units 128\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 1034s - loss: 0.1581 - acc: 0.9691 - val_loss: 0.1253 - val_acc: 0.9708\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 1030s - loss: 0.0784 - acc: 0.9747 - val_loss: 0.0547 - val_acc: 0.9800\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 1033s - loss: 0.0397 - acc: 0.9866 - val_loss: 0.0509 - val_acc: 0.9834\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 1032s - loss: 0.0299 - acc: 0.9907 - val_loss: 0.0550 - val_acc: 0.9824\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 1033s - loss: 0.0240 - acc: 0.9928 - val_loss: 0.0626 - val_acc: 0.9825\n",
      "22:06:22 Best Xval loss epoch 2, value 0.050938\n",
      "22:06:22 Finished (unfrozen)...\n",
      "LSTM units 128\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "22:12:00 Train Accuracy 0.995, Train F1 0.917, f_score 0.919 (beta 0.667)\n",
      "[[127186    317]\n",
      " [   274   3274]]\n",
      "22:13:53 Xval Accuracy 0.983, Xval F1 0.681, f_score 0.698 (beta 0.667)\n",
      "[[42105   458]\n",
      " [  306   815]]\n",
      "Raw score 2 0.011652\n",
      "22:13:53 Saving...\n"
     ]
    }
   ],
   "source": [
    "# grid search - no freeze - train embeddings, stop when xval loss reaches a minimum\n",
    "embedding_vector_length = EMBEDDING_DIM\n",
    "\n",
    "for sig_reg_penalty in [0.00003]:\n",
    "    for dropout in [0.333]:\n",
    "        for lstm_units in [16, 32, 64, 128]:\n",
    "            for lstm_reg_penalty in [0.00000,]:\n",
    "                #0.000001, 0.000003, 0.00001, 0.00003]:\n",
    "                models = []\n",
    "                xval_losses = []\n",
    "\n",
    "                model = create_model(lstm_size=lstm_units, \n",
    "                                     lstm_reg_penalty=lstm_reg_penalty, \n",
    "                                     sigmoid_dropout=dropout, \n",
    "                                     sigmoid_reg_penalty=sig_reg_penalty)\n",
    "                print('%s Starting (unfrozen)...' % time.strftime(\"%H:%M:%S\"))\n",
    "                print (\"LSTM units %d\" % lstm_units)\n",
    "                print (\"LSTM reg_penalty %.8f\" % lstm_reg_penalty)\n",
    "                print (\"Sigmoid dropout %.4f\" %  dropout)\n",
    "                print (\"Sigmoid reg_penalty %.8f\" % sig_reg_penalty)\n",
    "\n",
    "                ##################################################################\n",
    "                # train end-to-end including embeddings until xval loss bottoms out\n",
    "                ##################################################################\n",
    "                \n",
    "                epochs = 10\n",
    "                for _ in range(epochs):\n",
    "                    fit = model.fit(X_train, y_train, validation_data=(X_xval, y_xval), epochs=1, batch_size=1024)\n",
    "                    # save loss\n",
    "                    train_loss = fit.history['loss'][-1]\n",
    "                    train_acc = fit.history['acc'][-1]\n",
    "                    xval_loss = fit.history['val_loss'][-1]\n",
    "                    xval_acc = fit.history['val_acc'][-1]\n",
    "                    xval_losses.append(xval_loss)\n",
    "                    models.append(copy.copy(model))\n",
    "\n",
    "                    bestloss_index = np.argmin(xval_losses)\n",
    "                    bestloss_value = xval_losses[bestloss_index]\n",
    "\n",
    "                    # break if loss rises by 10% from best\n",
    "                    if xval_loss / bestloss_value > 1.1:\n",
    "                        break\n",
    "                    \n",
    "                # keep model from epoch with best xval loss\n",
    "                print (\"%s Best Xval loss epoch %d, value %f\" % (time.strftime(\"%H:%M:%S\"), bestloss_index, bestloss_value))\n",
    "                \n",
    "                model = models[bestloss_index]\n",
    "\n",
    "                print('%s Finished (unfrozen)...' % time.strftime(\"%H:%M:%S\"))\n",
    "                print (\"LSTM units %d\" % lstm_units)\n",
    "                print (\"LSTM reg_penalty %.8f\" % lstm_reg_penalty)\n",
    "                print (\"Sigmoid dropout %.4f\" %  dropout)\n",
    "                print (\"Sigmoid reg_penalty %.8f\" % sig_reg_penalty)                \n",
    "                \n",
    "                y_train_prob = model.predict(X_train)\n",
    "                \n",
    "                beta=(2.0/3.0) # penalize false positives more than false negatives\n",
    "                thresh, score = selectThreshold(y_train_prob, y_train, beta=beta)\n",
    "                y_train_pred = y_train_prob >= thresh\n",
    "\n",
    "                print(\"%s Train Accuracy %.3f, Train F1 %.3f, f_score %.3f (beta %.3f)\" % \n",
    "                      (time.strftime(\"%H:%M:%S\"),\n",
    "                       sklearn.metrics.accuracy_score(y_train_pred, y_train), \n",
    "                       sklearn.metrics.f1_score(y_train_pred, y_train),\n",
    "                       score, beta))\n",
    "                \n",
    "                print(sklearn.metrics.confusion_matrix(y_train_pred, y_train))\n",
    "\n",
    "                y_xval_prob = model.predict(X_xval)\n",
    "                \n",
    "                thresh, score = selectThreshold(y_xval_prob, y_xval, beta=beta)\n",
    "                y_xval_pred = y_xval_prob >= thresh\n",
    "                \n",
    "                print(\"%s Xval Accuracy %.3f, Xval F1 %.3f, f_score %.3f (beta %.3f)\" % \n",
    "                      (time.strftime(\"%H:%M:%S\"),\n",
    "                       sklearn.metrics.accuracy_score(y_xval_pred, y_xval), \n",
    "                       sklearn.metrics.f1_score(y_xval_pred, y_xval),\n",
    "                       score, beta))\n",
    "                \n",
    "                confusion_matrix = sklearn.metrics.confusion_matrix(y_xval_pred, y_xval)\n",
    "                print(confusion_matrix)\n",
    "                false_positive = confusion_matrix[1][0]\n",
    "                false_negative = confusion_matrix[0][1]\n",
    "                true_positive = confusion_matrix[1][1]\n",
    "                raw_score = 1.0 * (true_positive - false_positive) / np.sum(confusion_matrix)\n",
    "                print (\"Raw score 2 %f\" % raw_score)\n",
    "                \n",
    "                # save model to disk\n",
    "                print('%s Saving...' % time.strftime(\"%H:%M:%S\"))               \n",
    "                modelname = \"nofreeze_%d_%.6f_%.3f_%.6f\" % (lstm_units, lstm_reg_penalty, dropout, sig_reg_penalty)\n",
    "                model.save(\"%s.h5\" % modelname)\n",
    "                model.save_weights(\"%s_weights.h5\" % modelname)\n",
    "                with open(\"%s.json\" % modelname, \"wb\") as fjson:\n",
    "                    fjson.write(model.to_json()) \n",
    "                    \n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 16)                20288     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,020,605.0\n",
      "Trainable params: 20,305.0\n",
      "Non-trainable params: 3,000,300.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "22:23:52 Starting (unfrozen)...\n",
      "LSTM units 16\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 135s - loss: 0.3728 - acc: 0.9682 - val_loss: 0.1550 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 133s - loss: 0.1396 - acc: 0.9726 - val_loss: 0.1325 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 133s - loss: 0.1319 - acc: 0.9726 - val_loss: 0.1282 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 133s - loss: 0.1045 - acc: 0.9734 - val_loss: 0.0776 - val_acc: 0.9751\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 133s - loss: 0.0734 - acc: 0.9779 - val_loss: 0.0650 - val_acc: 0.9793\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 133s - loss: 0.0651 - acc: 0.9803 - val_loss: 0.0595 - val_acc: 0.9810\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 133s - loss: 0.0593 - acc: 0.9817 - val_loss: 0.0557 - val_acc: 0.9814\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 133s - loss: 0.0564 - acc: 0.9823 - val_loss: 0.0538 - val_acc: 0.9824\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 133s - loss: 0.0538 - acc: 0.9828 - val_loss: 0.0531 - val_acc: 0.9827\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 133s - loss: 0.0522 - acc: 0.9837 - val_loss: 0.0508 - val_acc: 0.9829\n",
      "22:46:12 Best Xval loss epoch 9, value 0.050836\n",
      "22:46:12 Finished (unfrozen)...\n",
      "LSTM units 16\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "22:47:34 Train Accuracy 0.984, Train F1 0.689, f_score 0.709 (beta 0.667)\n",
      "[[126661   1282]\n",
      " [   799   2309]]\n",
      "22:48:02 Xval Accuracy 0.983, Xval F1 0.666, f_score 0.710 (beta 0.667)\n",
      "[[42219   541]\n",
      " [  192   732]]\n",
      "Raw score 2 0.012362\n",
      "22:48:02 Saving...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 32)                42624     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,042,957.0\n",
      "Trainable params: 42,657.0\n",
      "Non-trainable params: 3,000,300.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "22:48:05 Starting (unfrozen)...\n",
      "LSTM units 32\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 232s - loss: 0.2605 - acc: 0.9652 - val_loss: 0.1311 - val_acc: 0.9710\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 230s - loss: 0.1245 - acc: 0.9726 - val_loss: 0.1213 - val_acc: 0.9710\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 229s - loss: 0.0974 - acc: 0.9738 - val_loss: 0.0711 - val_acc: 0.9762\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 230s - loss: 0.0662 - acc: 0.9784 - val_loss: 0.0620 - val_acc: 0.9786\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 230s - loss: 0.0599 - acc: 0.9800 - val_loss: 0.0571 - val_acc: 0.9803\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 229s - loss: 0.0555 - acc: 0.9814 - val_loss: 0.0536 - val_acc: 0.9816\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 230s - loss: 0.0526 - acc: 0.9823 - val_loss: 0.0523 - val_acc: 0.9829\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 230s - loss: 0.0510 - acc: 0.9830 - val_loss: 0.0501 - val_acc: 0.9831\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 230s - loss: 0.0491 - acc: 0.9836 - val_loss: 0.0498 - val_acc: 0.9833\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 230s - loss: 0.0480 - acc: 0.9840 - val_loss: 0.0499 - val_acc: 0.9824\n",
      "23:26:31 Best Xval loss epoch 8, value 0.049789\n",
      "23:26:31 Finished (unfrozen)...\n",
      "LSTM units 32\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "23:28:23 Train Accuracy 0.984, Train F1 0.682, f_score 0.714 (beta 0.667)\n",
      "[[126812   1397]\n",
      " [   648   2194]]\n",
      "23:29:01 Xval Accuracy 0.984, Xval F1 0.691, f_score 0.717 (beta 0.667)\n",
      "[[42159   468]\n",
      " [  252   805]]\n",
      "Raw score 2 0.012659\n",
      "23:29:01 Saving...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,093,805.0\n",
      "Trainable params: 93,505.0\n",
      "Non-trainable params: 3,000,300.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "23:29:04 Starting (unfrozen)...\n",
      "LSTM units 64\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 435s - loss: 0.1882 - acc: 0.9698 - val_loss: 0.0825 - val_acc: 0.9752\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 434s - loss: 0.0677 - acc: 0.9780 - val_loss: 0.0595 - val_acc: 0.9793\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 434s - loss: 0.0563 - acc: 0.9808 - val_loss: 0.0540 - val_acc: 0.9816\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131051/131051 [==============================] - 435s - loss: 0.0515 - acc: 0.9828 - val_loss: 0.0519 - val_acc: 0.9822\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 537s - loss: 0.0498 - acc: 0.9832 - val_loss: 0.0505 - val_acc: 0.9832\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 544s - loss: 0.0487 - acc: 0.9838 - val_loss: 0.0497 - val_acc: 0.9828\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 534s - loss: 0.0478 - acc: 0.9841 - val_loss: 0.0487 - val_acc: 0.9834\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 542s - loss: 0.0467 - acc: 0.9845 - val_loss: 0.0485 - val_acc: 0.9835\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 543s - loss: 0.0465 - acc: 0.9843 - val_loss: 0.0484 - val_acc: 0.9834\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 545s - loss: 0.0454 - acc: 0.9848 - val_loss: 0.0485 - val_acc: 0.9832\n",
      "00:52:14 Best Xval loss epoch 8, value 0.048431\n",
      "00:52:14 Finished (unfrozen)...\n",
      "LSTM units 64\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "00:56:09 Train Accuracy 0.986, Train F1 0.700, f_score 0.738 (beta 0.667)\n",
      "[[126932   1371]\n",
      " [   528   2220]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in divide\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:57:27 Xval Accuracy 0.984, Xval F1 0.682, f_score 0.720 (beta 0.667)\n",
      "[[42207   509]\n",
      " [  204   764]]\n",
      "Raw score 2 0.012819\n",
      "00:57:27 Saving...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,220,077.0\n",
      "Trainable params: 219,777.0\n",
      "Non-trainable params: 3,000,300.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "00:57:31 Starting (unfrozen)...\n",
      "LSTM units 128\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 1135s - loss: 0.1616 - acc: 0.9672 - val_loss: 0.1306 - val_acc: 0.9710\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 1133s - loss: 0.1255 - acc: 0.9727 - val_loss: 0.1301 - val_acc: 0.9710\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 1131s - loss: 0.1250 - acc: 0.9727 - val_loss: 0.1293 - val_acc: 0.9710\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      " 37888/131051 [=======>......................] - ETA: 706s - loss: 0.1180 - acc: 0.9736"
     ]
    }
   ],
   "source": [
    "# grid search - freeze embeddings - use pre-trained embeddings, train LSTM/sigmoid only, stop when xval loss reaches a minimum\n",
    "embedding_vector_length = EMBEDDING_DIM\n",
    "\n",
    "for sig_reg_penalty in [0.00003]:\n",
    "    for dropout in [0.333]:\n",
    "        for lstm_units in [16, 32, 64, 128]:\n",
    "            for lstm_reg_penalty in [0.00000,]:\n",
    "                #0.000001, 0.000003, 0.00001, 0.00003]:\n",
    "                models = []\n",
    "                xval_losses = []\n",
    "\n",
    "                model = create_model(lstm_size=lstm_units, \n",
    "                                     lstm_reg_penalty=lstm_reg_penalty, \n",
    "                                     sigmoid_dropout=dropout, \n",
    "                                     sigmoid_reg_penalty=sig_reg_penalty,\n",
    "                                     train_embed=False)\n",
    "                print('%s Starting (unfrozen)...' % time.strftime(\"%H:%M:%S\"))\n",
    "                print (\"LSTM units %d\" % lstm_units)\n",
    "                print (\"LSTM reg_penalty %.8f\" % lstm_reg_penalty)\n",
    "                print (\"Sigmoid dropout %.4f\" %  dropout)\n",
    "                print (\"Sigmoid reg_penalty %.8f\" % sig_reg_penalty)\n",
    "\n",
    "                ##################################################################\n",
    "                # train end-to-end including embeddings until xval loss bottoms out\n",
    "                ##################################################################\n",
    "                \n",
    "                epochs = 10\n",
    "                for _ in range(epochs):\n",
    "                    fit = model.fit(X_train, y_train, validation_data=(X_xval, y_xval), epochs=1, batch_size=1024)\n",
    "                    # save loss\n",
    "                    train_loss = fit.history['loss'][-1]\n",
    "                    train_acc = fit.history['acc'][-1]\n",
    "                    xval_loss = fit.history['val_loss'][-1]\n",
    "                    xval_acc = fit.history['val_acc'][-1]\n",
    "                    xval_losses.append(xval_loss)\n",
    "                    models.append(copy.copy(model))\n",
    "\n",
    "                    bestloss_index = np.argmin(xval_losses)\n",
    "                    bestloss_value = xval_losses[bestloss_index]\n",
    "\n",
    "                    # break if loss rises by 10% from best\n",
    "                    if xval_loss / bestloss_value > 1.1:\n",
    "                        break\n",
    "                    \n",
    "                # keep model from epoch with best xval loss\n",
    "                print (\"%s Best Xval loss epoch %d, value %f\" % (time.strftime(\"%H:%M:%S\"), bestloss_index, bestloss_value))\n",
    "                \n",
    "                model = models[bestloss_index]\n",
    "\n",
    "                print('%s Finished (frozen)...' % time.strftime(\"%H:%M:%S\"))\n",
    "                print (\"LSTM units %d\" % lstm_units)\n",
    "                print (\"LSTM reg_penalty %.8f\" % lstm_reg_penalty)\n",
    "                print (\"Sigmoid dropout %.4f\" %  dropout)\n",
    "                print (\"Sigmoid reg_penalty %.8f\" % sig_reg_penalty)                \n",
    "                \n",
    "                y_train_prob = model.predict(X_train)\n",
    "                \n",
    "                beta=(2.0/3.0) # penalize false positives more than false negatives\n",
    "                thresh, score = selectThreshold(y_train_prob, y_train, beta=beta)\n",
    "                y_train_pred = y_train_prob >= thresh\n",
    "\n",
    "                print(\"%s Train Accuracy %.3f, Train F1 %.3f, f_score %.3f (beta %.3f)\" % \n",
    "                      (time.strftime(\"%H:%M:%S\"),\n",
    "                       sklearn.metrics.accuracy_score(y_train_pred, y_train), \n",
    "                       sklearn.metrics.f1_score(y_train_pred, y_train),\n",
    "                       score, beta))\n",
    "                \n",
    "                print(sklearn.metrics.confusion_matrix(y_train_pred, y_train))\n",
    "\n",
    "                y_xval_prob = model.predict(X_xval)\n",
    "                \n",
    "                thresh, score = selectThreshold(y_xval_prob, y_xval, beta=beta)\n",
    "                y_xval_pred = y_xval_prob >= thresh\n",
    "                \n",
    "                print(\"%s Xval Accuracy %.3f, Xval F1 %.3f, f_score %.3f (beta %.3f)\" % \n",
    "                      (time.strftime(\"%H:%M:%S\"),\n",
    "                       sklearn.metrics.accuracy_score(y_xval_pred, y_xval), \n",
    "                       sklearn.metrics.f1_score(y_xval_pred, y_xval),\n",
    "                       score, beta))\n",
    "                \n",
    "                confusion_matrix = sklearn.metrics.confusion_matrix(y_xval_pred, y_xval)\n",
    "                print(confusion_matrix)\n",
    "                false_positive = confusion_matrix[1][0]\n",
    "                false_negative = confusion_matrix[0][1]\n",
    "                true_positive = confusion_matrix[1][1]\n",
    "                raw_score = 1.0 * (true_positive - false_positive) / np.sum(confusion_matrix)\n",
    "                print (\"Raw score 2 %f\" % raw_score)\n",
    "                \n",
    "                # save model to disk\n",
    "                print('%s Saving...' % time.strftime(\"%H:%M:%S\"))               \n",
    "                modelname = \"freeze_%d_%.6f_%.3f_%.6f\" % (lstm_units, lstm_reg_penalty, dropout, sig_reg_penalty)\n",
    "                model.save(\"%s.h5\" % modelname)\n",
    "                model.save_weights(\"%s_weights.h5\" % modelname)\n",
    "                with open(\"%s.json\" % modelname, \"wb\") as fjson:\n",
    "                    fjson.write(model.to_json()) \n",
    "                    \n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best model and evaluate in test set\n",
    "\n",
    "modelname = \"freeze_%d_%.6f_%.3f_%.6f\" % (128, 0.000000, 0.333, 0.000030)\n",
    "\n",
    "# doesn't work because of some custom metric BS\n",
    "#keras.models.load_model(\"%s.h5\" % modelname)\n",
    "\n",
    "with open(\"%s.json\" % modelname, 'r') as json_file:\n",
    "    model_json = json_file.read()\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(\"%s_weights.h5\" % modelname)\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "\n",
    "y_test_prob = model.predict(X_test)\n",
    "beta=(2.0/3.0) # penalize false positives more than false negatives\n",
    "\n",
    "y_test_pred = y_test_prob >= thresh\n",
    "print(\"Test Accuracy %.3f, Test F1 %.3f, f_score %.3f (beta %.3f)\" % \n",
    "                      (sklearn.metrics.accuracy_score(y_test_pred, y_test), \n",
    "                       sklearn.metrics.f1_score(y_test_pred, y_test),\n",
    "                       score, beta))\n",
    "                \n",
    "print(sklearn.metrics.confusion_matrix(y_test_pred, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
