{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import sklearn\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.regularizers import l1\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "\n",
    "# create session explicitly and keep a reference\n",
    "# so we can access and evaluate tensors directly \n",
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global config variables \n",
    "model_name = \"streeteye_lstm\"\n",
    "#data_file = \"lstm_dump_test.txt\"\n",
    "data_file = \"dump_2017_words.txt\"\n",
    "\n",
    "checkpoint_dir = \"/home/ubuntu/mount/Notebooks/checkpoints\"\n",
    "tensorboard_dir =\"/home/ubuntu/mount/Notebooks/tensorboard\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded data.\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "# 1. load data\n",
    "############################################################\n",
    "\n",
    "# load dataset\n",
    "print(\"Loading data...\")\n",
    "data=[]\n",
    "y=[]\n",
    "\n",
    "# count words\n",
    "c = collections.Counter()\n",
    "\n",
    "with open(data_file, \"r\") as infile:\n",
    "    for line in infile:\n",
    "        l = line.rstrip('\\n').split(\",\")\n",
    "        label = l.pop(0)\n",
    "        # skip empty headlines\n",
    "        if len(l[0]) == 0:\n",
    "            continue\n",
    "        if '' in l:\n",
    "            l = [w for w in l if w]\n",
    "        data.append(l)\n",
    "        y.append(label)\n",
    "        c.update(l)\n",
    "        \n",
    "print(\"Loaded data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['UNK', -1], ('domain_otherdomain', 119708), ('subsource_othersubsource', 47862), ('trump', 21141), ('with', 10761), ('domain_youtube.com', 8908), ('us', 8434), ('2017', 7862), ('from', 7768), ('subsource_memeorandum', 7712)]\n",
      "[('hazard', 17), ('alexei', 17), ('molly', 17), ('expel', 17), ('champ', 17), ('admiral', 17), ('conversational', 17), ('memorable', 17), ('wharton', 17), ('torn', 17)]\n"
     ]
    }
   ],
   "source": [
    "# create a list of top words        \n",
    "vocabulary_size = 10000 # set this to have ~20 for least popular\n",
    "count = [['UNK', -1]]\n",
    "count.extend(c.most_common(vocabulary_size - 1))\n",
    "print(count[:10])\n",
    "print(count[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = dict()\n",
    "# map words into a dict of ints\n",
    "for word, _ in count:\n",
    "    dictionary[word] = len(dictionary)\n",
    "\n",
    "data_embeddings=[]\n",
    "unk_count = 0\n",
    "\n",
    "for obs in data:\n",
    "    embedlist = []\n",
    "    for word in obs:\n",
    "        if word in dictionary:\n",
    "            index = dictionary[word]\n",
    "        else:\n",
    "            index = 0  # dictionary['UNK']\n",
    "            unk_count = unk_count + 1\n",
    "        embedlist.append(index)\n",
    "    data_embeddings.append(embedlist)\n",
    "        \n",
    "count[0][1] = unk_count\n",
    "reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "trump\n"
     ]
    }
   ],
   "source": [
    "print(dictionary['trump'])\n",
    "print(reverse_dictionary[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7ff3ed1b0c90>]], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEICAYAAACj2qi6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqZuhIUnq9n9K8+wLvazDjAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff3ed1b0450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ls = (map(len, data_embeddings))\n",
    "pd.DataFrame(ls).hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218419, 120)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LENGTH = 120\n",
    "X = sequence.pad_sequences(data_embeddings, maxlen=MAX_LENGTH)\n",
    "X[0]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(218419, 1)\n",
      "Observations: 218419\n",
      "Features: 120\n",
      "Split into training, temp\n",
      "Split into xval, test\n"
     ]
    }
   ],
   "source": [
    "y=np.array(np.float32(y))\n",
    "\n",
    "y=y.reshape((y.shape[0],1))\n",
    "print(y.shape)\n",
    "num_labels=1\n",
    "\n",
    "num_obs, num_features = X.shape\n",
    "print(\"Observations: %d\\nFeatures: %d\" % (num_obs, num_features))\n",
    "\n",
    "# split into training, xval, test, 60/20/20\n",
    "print(\"Split into training, temp\")\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4)\n",
    "print(\"Split into xval, test\")\n",
    "X_xval, X_test, y_xval, y_test = train_test_split(X_temp, y_temp, test_size=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set\n",
      "(131051, 120)\n",
      "Xval set\n",
      "(43684, 120)\n",
      "Test set\n",
      "(43684, 120)\n",
      "\n",
      "Training observations:  131051  \n",
      "Xval observations:  43684  \n",
      "Test observations:  43684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Training set\")\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"Xval set\")\n",
    "print(X_xval.shape)\n",
    "\n",
    "print(\"Test set\")\n",
    "print(X_test.shape)\n",
    "\n",
    "num_training_samples = X_train.shape[0]\n",
    "num_xval_samples = X_xval.shape[0]\n",
    "num_test_samples = X_test.shape[0]\n",
    "\n",
    "print (\"\\nTraining observations:  %d  \\nXval observations:  %d  \\nTest observations:  %d\\n\" % (num_training_samples, num_xval_samples, num_test_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize embeddings to pre-trained vals\n",
    "pkl_file = open('embeddings.pkl', 'rb')\n",
    "embeddings_dict, embeddings_reverse_dict, embeddings_data = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized 10000 embeddings\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM=300\n",
    "\n",
    "# +1 seems like an off-by-one somewhere\n",
    "embedding_matrix = np.zeros((len(dictionary) + 1, EMBEDDING_DIM))\n",
    "\n",
    "count = 0\n",
    "for word, i in dictionary.items():\n",
    "    #print(word)\n",
    "    embed_i = embeddings_dict.get(word)\n",
    "    if embed_i is not None:\n",
    "        embedding_vector = embeddings_data[i]\n",
    "        count +=1\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "print(\"initialized %d embeddings\" % count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to generate model\n",
    "\n",
    "def create_model(lstm_size=30, lstm_reg_penalty=0.0, sigmoid_dropout=(1.0/3.0), sigmoid_reg_penalty=0.0001):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Embedding(len(dictionary) + 1, \n",
    "                        embedding_vector_length, \n",
    "                        weights=[embedding_matrix],\n",
    "                        input_length=MAX_LENGTH,\n",
    "                        trainable=True))\n",
    "    \n",
    "    # LSTM with lstm_size units\n",
    "    model.add(LSTM(lstm_size,\n",
    "                   kernel_regularizer=l1(lstm_reg_penalty)))\n",
    "    model.add(Dropout(sigmoid_dropout))\n",
    "    \n",
    "    model.add(Dense(1, \n",
    "                    activation='sigmoid',\n",
    "                    kernel_initializer='TruncatedNormal', \n",
    "                    kernel_regularizer=l1(sigmoid_reg_penalty)))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def selectThreshold (logits, labels, beta=(2.0/3)):\n",
    "    # return threshold, f-score that yields best F-score\n",
    "    # predict using true if >= threshold\n",
    "\n",
    "    precision, recall, thresholds = sklearn.metrics.precision_recall_curve(labels, logits)\n",
    "    bb = beta**2\n",
    "    f1_scores = (1 + bb) * precision * recall / (bb * precision + recall)\n",
    "    f1_scores = np.nan_to_num(f1_scores)\n",
    "    \n",
    "    best_index = np.argmax(f1_scores)\n",
    "    best_threshold = thresholds[best_index]\n",
    "    best_score = f1_scores[best_index]\n",
    "    return (best_threshold, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 16)                20288     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,020,605.0\n",
      "Trainable params: 3,020,605.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "15:34:24 Starting (unfrozen)...\n",
      "LSTM units 16\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 166s - loss: 0.3157 - acc: 0.9652 - val_loss: 0.1442 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 165s - loss: 0.1367 - acc: 0.9726 - val_loss: 0.1324 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 165s - loss: 0.1296 - acc: 0.9726 - val_loss: 0.1316 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 164s - loss: 0.1236 - acc: 0.9726 - val_loss: 0.1077 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 165s - loss: 0.0676 - acc: 0.9814 - val_loss: 0.0544 - val_acc: 0.9846\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 165s - loss: 0.0466 - acc: 0.9878 - val_loss: 0.0514 - val_acc: 0.9844\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 165s - loss: 0.0360 - acc: 0.9911 - val_loss: 0.0567 - val_acc: 0.9837\n",
      "15:53:44 Best Xval loss epoch 5, value 0.051361\n",
      "15:53:44 Finished (unfrozen)...\n",
      "LSTM units 16\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "15:55:04 Train Accuracy 0.994, Train F1 0.893, f_score 0.910 (beta 0.667)\n",
      "[[127264    539]\n",
      " [   196   3052]]\n",
      "15:55:30 Xval Accuracy 0.984, Xval F1 0.680, f_score 0.721 (beta 0.667)\n",
      "[[42220   518]\n",
      " [  191   755]]\n",
      "Raw score 2 0.012911\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 16)                20288     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,020,605.0\n",
      "Trainable params: 20,305.0\n",
      "Non-trainable params: 3,000,300.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "15:55:30 Continuing (frozen)...\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 133s - loss: 0.0252 - acc: 0.9944 - val_loss: 0.0625 - val_acc: 0.9825\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 132s - loss: 0.0228 - acc: 0.9947 - val_loss: 0.0639 - val_acc: 0.9824\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 132s - loss: 0.0222 - acc: 0.9949 - val_loss: 0.0663 - val_acc: 0.9826\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 132s - loss: 0.0219 - acc: 0.9950 - val_loss: 0.0677 - val_acc: 0.9826\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 132s - loss: 0.0215 - acc: 0.9953 - val_loss: 0.0685 - val_acc: 0.9825\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 132s - loss: 0.0208 - acc: 0.9953 - val_loss: 0.0696 - val_acc: 0.9826\n",
      "16:08:50 Best Xval loss epoch 0, value 0.062450\n",
      "16:08:50 Finished (frozen)...\n",
      "LSTM units 16\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "16:10:09 Train Accuracy 0.996, Train F1 0.918, f_score 0.934 (beta 0.667)\n",
      "[[127330    435]\n",
      " [   130   3156]]\n",
      "16:10:35 Xval Accuracy 0.983, Xval F1 0.667, f_score 0.702 (beta 0.667)\n",
      "[[42181   521]\n",
      " [  230   752]]\n",
      "Raw score 2 0.011949\n",
      "16:10:35 Saving...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 32)                42624     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,042,957.0\n",
      "Trainable params: 3,042,957.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "16:10:38 Starting (unfrozen)...\n",
      "LSTM units 32\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 276s - loss: 0.2541 - acc: 0.9683 - val_loss: 0.1318 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 274s - loss: 0.1214 - acc: 0.9726 - val_loss: 0.1156 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 274s - loss: 0.0893 - acc: 0.9730 - val_loss: 0.0608 - val_acc: 0.9763\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 274s - loss: 0.0475 - acc: 0.9845 - val_loss: 0.0508 - val_acc: 0.9843\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 274s - loss: 0.0342 - acc: 0.9900 - val_loss: 0.0536 - val_acc: 0.9839\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 274s - loss: 0.0266 - acc: 0.9929 - val_loss: 0.0565 - val_acc: 0.9825\n",
      "16:38:08 Best Xval loss epoch 3, value 0.050791\n",
      "16:38:08 Finished (unfrozen)...\n",
      "LSTM units 32\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "16:39:58 Train Accuracy 0.996, Train F1 0.920, f_score 0.930 (beta 0.667)\n",
      "[[127279    376]\n",
      " [   181   3215]]\n",
      "16:40:35 Xval Accuracy 0.983, Xval F1 0.687, f_score 0.703 (beta 0.667)\n",
      "[[42107   448]\n",
      " [  304   825]]\n",
      "Raw score 2 0.011927\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 32)                42624     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,042,957.0\n",
      "Trainable params: 42,657.0\n",
      "Non-trainable params: 3,000,300.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "16:40:36 Continuing (frozen)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 230s - loss: 0.0181 - acc: 0.9957 - val_loss: 0.0698 - val_acc: 0.9817\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 228s - loss: 0.0167 - acc: 0.9961 - val_loss: 0.0726 - val_acc: 0.9824\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 228s - loss: 0.0159 - acc: 0.9963 - val_loss: 0.0765 - val_acc: 0.9820\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 228s - loss: 0.0153 - acc: 0.9963 - val_loss: 0.0820 - val_acc: 0.9824\n",
      "16:55:54 Best Xval loss epoch 0, value 0.069758\n",
      "16:55:54 Finished (frozen)...\n",
      "LSTM units 32\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "16:57:44 Train Accuracy 0.997, Train F1 0.937, f_score 0.944 (beta 0.667)\n",
      "[[127312    298]\n",
      " [   148   3293]]\n",
      "16:58:21 Xval Accuracy 0.983, Xval F1 0.659, f_score 0.700 (beta 0.667)\n",
      "[[42204   546]\n",
      " [  207   727]]\n",
      "Raw score 2 0.011904\n",
      "16:58:21 Saving...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,093,805.0\n",
      "Trainable params: 3,093,805.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "16:58:24 Starting (unfrozen)...\n",
      "LSTM units 64\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 510s - loss: 0.1889 - acc: 0.9692 - val_loss: 0.1309 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 510s - loss: 0.1171 - acc: 0.9726 - val_loss: 0.1057 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 512s - loss: 0.0664 - acc: 0.9759 - val_loss: 0.0533 - val_acc: 0.9831\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 512s - loss: 0.0387 - acc: 0.9872 - val_loss: 0.0524 - val_acc: 0.9842\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 508s - loss: 0.0286 - acc: 0.9914 - val_loss: 0.0598 - val_acc: 0.9828\n",
      "17:41:00 Best Xval loss epoch 3, value 0.052393\n",
      "17:41:00 Finished (unfrozen)...\n",
      "LSTM units 64\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "17:43:59 Train Accuracy 0.995, Train F1 0.904, f_score 0.910 (beta 0.667)\n",
      "[[127176    392]\n",
      " [   284   3199]]\n",
      "17:44:59 Xval Accuracy 0.983, Xval F1 0.653, f_score 0.704 (beta 0.667)\n",
      "[[42241   574]\n",
      " [  170   699]]\n",
      "Raw score 2 0.012110\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,093,805.0\n",
      "Trainable params: 93,505.0\n",
      "Non-trainable params: 3,000,300.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "17:44:59 Continuing (frozen)...\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 445s - loss: 0.0195 - acc: 0.9948 - val_loss: 0.0717 - val_acc: 0.9820\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 445s - loss: 0.0182 - acc: 0.9953 - val_loss: 0.0757 - val_acc: 0.9826\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 445s - loss: 0.0172 - acc: 0.9955 - val_loss: 0.0782 - val_acc: 0.9804\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 445s - loss: 0.0167 - acc: 0.9955 - val_loss: 0.0860 - val_acc: 0.9824\n",
      "18:14:43 Best Xval loss epoch 0, value 0.071692\n",
      "18:14:43 Finished (frozen)...\n",
      "LSTM units 64\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "18:17:42 Train Accuracy 0.996, Train F1 0.924, f_score 0.930 (beta 0.667)\n",
      "[[127245    320]\n",
      " [   215   3271]]\n",
      "18:18:42 Xval Accuracy 0.982, Xval F1 0.641, f_score 0.692 (beta 0.667)\n",
      "[[42231   587]\n",
      " [  180   686]]\n",
      "Raw score 2 0.011583\n",
      "18:18:42 Saving...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,220,077.0\n",
      "Trainable params: 3,220,077.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "18:18:45 Starting (unfrozen)...\n",
      "LSTM units 128\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 1061s - loss: 0.1580 - acc: 0.9695 - val_loss: 0.1286 - val_acc: 0.9710\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 1060s - loss: 0.0819 - acc: 0.9754 - val_loss: 0.0526 - val_acc: 0.9826\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 1057s - loss: 0.0395 - acc: 0.9873 - val_loss: 0.0508 - val_acc: 0.9828\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 1058s - loss: 0.0302 - acc: 0.9905 - val_loss: 0.0554 - val_acc: 0.9829\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 1059s - loss: 0.0235 - acc: 0.9930 - val_loss: 0.0657 - val_acc: 0.9825\n",
      "19:47:03 Best Xval loss epoch 2, value 0.050802\n",
      "19:47:03 Finished (unfrozen)...\n",
      "LSTM units 128\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "19:52:42 Train Accuracy 0.996, Train F1 0.921, f_score 0.925 (beta 0.667)\n",
      "[[127220    320]\n",
      " [   240   3271]]\n",
      "19:54:35 Xval Accuracy 0.983, Xval F1 0.659, f_score 0.696 (beta 0.667)\n",
      "[[42185   536]\n",
      " [  226   737]]\n",
      "Raw score 2 0.011698\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,220,077.0\n",
      "Trainable params: 219,777.0\n",
      "Non-trainable params: 3,000,300.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "19:54:35 Continuing (frozen)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 932s - loss: 0.0169 - acc: 0.9953 - val_loss: 0.0868 - val_acc: 0.9820\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 931s - loss: 0.0159 - acc: 0.9956 - val_loss: 0.0752 - val_acc: 0.9806\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 931s - loss: 0.0150 - acc: 0.9959 - val_loss: 0.0764 - val_acc: 0.9804\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 931s - loss: 0.0146 - acc: 0.9959 - val_loss: 0.0774 - val_acc: 0.9805\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 928s - loss: 0.0138 - acc: 0.9964 - val_loss: 0.0822 - val_acc: 0.9819\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 929s - loss: 0.0134 - acc: 0.9963 - val_loss: 0.0806 - val_acc: 0.9818\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 925s - loss: 0.0127 - acc: 0.9965 - val_loss: 0.0819 - val_acc: 0.9807\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 923s - loss: 0.0123 - acc: 0.9966 - val_loss: 0.0873 - val_acc: 0.9818\n",
      "21:58:32 Best Xval loss epoch 1, value 0.075232\n",
      "21:58:32 Finished (frozen)...\n",
      "LSTM units 128\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.3330\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "22:04:05 Train Accuracy 0.997, Train F1 0.941, f_score 0.949 (beta 0.667)\n",
      "[[127334    288]\n",
      " [   126   3303]]\n",
      "22:05:57 Xval Accuracy 0.983, Xval F1 0.647, f_score 0.695 (beta 0.667)\n",
      "[[42225   576]\n",
      " [  186   697]]\n",
      "Raw score 2 0.011698\n",
      "22:05:57 Saving...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 16)                20288     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,020,605.0\n",
      "Trainable params: 3,020,605.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "22:06:00 Starting (unfrozen)...\n",
      "LSTM units 16\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.5000\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 166s - loss: 0.3327 - acc: 0.9689 - val_loss: 0.1525 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 164s - loss: 0.1477 - acc: 0.9726 - val_loss: 0.1334 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 164s - loss: 0.1370 - acc: 0.9726 - val_loss: 0.1318 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 164s - loss: 0.1331 - acc: 0.9726 - val_loss: 0.1320 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 164s - loss: 0.1026 - acc: 0.9751 - val_loss: 0.0607 - val_acc: 0.9833\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 164s - loss: 0.0600 - acc: 0.9853 - val_loss: 0.0533 - val_acc: 0.9843\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 164s - loss: 0.0460 - acc: 0.9890 - val_loss: 0.0506 - val_acc: 0.9842\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 164s - loss: 0.0364 - acc: 0.9920 - val_loss: 0.0570 - val_acc: 0.9835\n",
      "22:28:00 Best Xval loss epoch 6, value 0.050587\n",
      "22:28:00 Finished (unfrozen)...\n",
      "LSTM units 16\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.5000\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "22:29:21 Train Accuracy 0.995, Train F1 0.907, f_score 0.923 (beta 0.667)\n",
      "[[127291    468]\n",
      " [   169   3123]]\n",
      "22:29:48 Xval Accuracy 0.984, Xval F1 0.691, f_score 0.720 (beta 0.667)\n",
      "[[42175   477]\n",
      " [  236   796]]\n",
      "Raw score 2 0.012819\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 16)                20288     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,020,605.0\n",
      "Trainable params: 20,305.0\n",
      "Non-trainable params: 3,000,300.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "22:29:48 Continuing (frozen)...\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 134s - loss: 0.0263 - acc: 0.9946 - val_loss: 0.0657 - val_acc: 0.9830\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 132s - loss: 0.0237 - acc: 0.9949 - val_loss: 0.0729 - val_acc: 0.9832\n",
      "22:34:17 Best Xval loss epoch 0, value 0.065723\n",
      "22:34:17 Finished (frozen)...\n",
      "LSTM units 16\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.5000\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "22:35:38 Train Accuracy 0.995, Train F1 0.914, f_score 0.928 (beta 0.667)\n",
      "[[127294    428]\n",
      " [   166   3163]]\n",
      "22:36:06 Xval Accuracy 0.983, Xval F1 0.690, f_score 0.712 (beta 0.667)\n",
      "[[42141   461]\n",
      " [  270   812]]\n",
      "Raw score 2 0.012407\n",
      "22:36:06 Saving...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 32)                42624     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,042,957.0\n",
      "Trainable params: 3,042,957.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "22:36:09 Starting (unfrozen)...\n",
      "LSTM units 32\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.5000\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 272s - loss: 0.2467 - acc: 0.9661 - val_loss: 0.1318 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 269s - loss: 0.1310 - acc: 0.9726 - val_loss: 0.1312 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 270s - loss: 0.1230 - acc: 0.9726 - val_loss: 0.1127 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 269s - loss: 0.0702 - acc: 0.9789 - val_loss: 0.0531 - val_acc: 0.9837\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131051/131051 [==============================] - 269s - loss: 0.0421 - acc: 0.9875 - val_loss: 0.0498 - val_acc: 0.9839\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 269s - loss: 0.0316 - acc: 0.9910 - val_loss: 0.0576 - val_acc: 0.9836\n",
      "23:03:11 Best Xval loss epoch 4, value 0.049847\n",
      "23:03:11 Finished (unfrozen)...\n",
      "LSTM units 32\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.5000\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "23:05:02 Train Accuracy 0.994, Train F1 0.897, f_score 0.907 (beta 0.667)\n",
      "[[127206    467]\n",
      " [   254   3124]]\n",
      "23:05:39 Xval Accuracy 0.984, Xval F1 0.685, f_score 0.720 (beta 0.667)\n",
      "[[42197   499]\n",
      " [  214   774]]\n",
      "Raw score 2 0.012819\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 32)                42624     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,042,957.0\n",
      "Trainable params: 42,657.0\n",
      "Non-trainable params: 3,000,300.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "23:05:40 Continuing (frozen)...\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 230s - loss: 0.0216 - acc: 0.9946 - val_loss: 0.0677 - val_acc: 0.9816\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 228s - loss: 0.0194 - acc: 0.9951 - val_loss: 0.0665 - val_acc: 0.9815\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 229s - loss: 0.0187 - acc: 0.9953 - val_loss: 0.0783 - val_acc: 0.9825\n",
      "23:17:10 Best Xval loss epoch 1, value 0.066464\n",
      "23:17:10 Finished (frozen)...\n",
      "LSTM units 32\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.5000\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "23:19:01 Train Accuracy 0.996, Train F1 0.920, f_score 0.926 (beta 0.667)\n",
      "[[127244    350]\n",
      " [   216   3241]]\n",
      "23:19:37 Xval Accuracy 0.983, Xval F1 0.651, f_score 0.698 (beta 0.667)\n",
      "[[42222   567]\n",
      " [  189   706]]\n",
      "Raw score 2 0.011835\n",
      "23:19:38 Saving...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,093,805.0\n",
      "Trainable params: 3,093,805.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "23:19:41 Starting (unfrozen)...\n",
      "LSTM units 64\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.5000\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 503s - loss: 0.1920 - acc: 0.9676 - val_loss: 0.1304 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 501s - loss: 0.1173 - acc: 0.9726 - val_loss: 0.1085 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 502s - loss: 0.0835 - acc: 0.9726 - val_loss: 0.0709 - val_acc: 0.9713\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 502s - loss: 0.0458 - acc: 0.9835 - val_loss: 0.0555 - val_acc: 0.9827\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 503s - loss: 0.0339 - acc: 0.9897 - val_loss: 0.0556 - val_acc: 0.9826\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 501s - loss: 0.0261 - acc: 0.9924 - val_loss: 0.0627 - val_acc: 0.9818\n",
      "00:09:59 Best Xval loss epoch 3, value 0.055457\n",
      "00:09:59 Finished (unfrozen)...\n",
      "LSTM units 64\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.5000\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "00:12:58 Train Accuracy 0.995, Train F1 0.911, f_score 0.920 (beta 0.667)\n",
      "[[127232    396]\n",
      " [   228   3195]]\n",
      "00:13:58 Xval Accuracy 0.982, Xval F1 0.662, f_score 0.692 (beta 0.667)\n",
      "[[42154   516]\n",
      " [  257   757]]\n",
      "Raw score 2 0.011446\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,093,805.0\n",
      "Trainable params: 93,505.0\n",
      "Non-trainable params: 3,000,300.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "00:13:58 Continuing (frozen)...\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 428s - loss: 0.0186 - acc: 0.9953 - val_loss: 0.0741 - val_acc: 0.9820\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 427s - loss: 0.0176 - acc: 0.9954 - val_loss: 0.0774 - val_acc: 0.9812\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 428s - loss: 0.0171 - acc: 0.9956 - val_loss: 0.0796 - val_acc: 0.9822\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 428s - loss: 0.0162 - acc: 0.9959 - val_loss: 0.0833 - val_acc: 0.9817\n",
      "00:42:33 Best Xval loss epoch 0, value 0.074064\n",
      "00:42:33 Finished (frozen)...\n",
      "LSTM units 64\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.5000\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "00:45:34 Train Accuracy 0.996, Train F1 0.928, f_score 0.935 (beta 0.667)\n",
      "[[127277    321]\n",
      " [   183   3270]]\n",
      "00:46:34 Xval Accuracy 0.982, Xval F1 0.638, f_score 0.681 (beta 0.667)\n",
      "[[42195   575]\n",
      " [  216   698]]\n",
      "Raw score 2 0.011034\n",
      "00:46:34 Saving...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,220,077.0\n",
      "Trainable params: 3,220,077.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "00:46:38 Starting (unfrozen)...\n",
      "LSTM units 128\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.5000\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131051/131051 [==============================] - 1047s - loss: 0.1575 - acc: 0.9689 - val_loss: 0.1249 - val_acc: 0.9709\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 1047s - loss: 0.0854 - acc: 0.9743 - val_loss: 0.0530 - val_acc: 0.9818\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 1047s - loss: 0.0400 - acc: 0.9867 - val_loss: 0.0505 - val_acc: 0.9826\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 1046s - loss: 0.0314 - acc: 0.9902 - val_loss: 0.0563 - val_acc: 0.9831\n",
      "01:56:27 Best Xval loss epoch 2, value 0.050534\n",
      "01:56:27 Finished (unfrozen)...\n",
      "LSTM units 128\n",
      "LSTM reg_penalty 0.00000000\n",
      "Sigmoid dropout 0.5000\n",
      "Sigmoid reg_penalty 0.00003000\n",
      "02:02:05 Train Accuracy 0.994, Train F1 0.886, f_score 0.896 (beta 0.667)\n",
      "[[127163    498]\n",
      " [   297   3093]]\n",
      "02:03:57 Xval Accuracy 0.983, Xval F1 0.679, f_score 0.714 (beta 0.667)\n",
      "[[42194   507]\n",
      " [  217   766]]\n",
      "Raw score 2 0.012568\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 120, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,220,077.0\n",
      "Trainable params: 219,777.0\n",
      "Non-trainable params: 3,000,300.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "02:03:57 Continuing (frozen)...\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 921s - loss: 0.0225 - acc: 0.9936 - val_loss: 0.0708 - val_acc: 0.9817\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 917s - loss: 0.0205 - acc: 0.9944 - val_loss: 0.0730 - val_acc: 0.9827\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      "131051/131051 [==============================] - 918s - loss: 0.0198 - acc: 0.9946 - val_loss: 0.0703 - val_acc: 0.9819\n",
      "Train on 131051 samples, validate on 43684 samples\n",
      "Epoch 1/1\n",
      " 73728/131051 [===============>..............] - ETA: 355s - loss: 0.0193 - acc: 0.9946"
     ]
    }
   ],
   "source": [
    "# grid search\n",
    "embedding_vector_length = EMBEDDING_DIM\n",
    "\n",
    "for sig_reg_penalty in [0.00003, 0.0003]:\n",
    "    for dropout in [0.333, 0.5]:\n",
    "        for lstm_units in [16, 32, 64, 128]:\n",
    "            for lstm_reg_penalty in [0.00000,]:\n",
    "                #0.000001, 0.000003, 0.00001, 0.00003]:\n",
    "                models = []\n",
    "                xval_losses = []\n",
    "\n",
    "                model = create_model(lstm_size=lstm_units, \n",
    "                                     lstm_reg_penalty=lstm_reg_penalty, \n",
    "                                     sigmoid_dropout=dropout, \n",
    "                                     sigmoid_reg_penalty=sig_reg_penalty)\n",
    "                print('%s Starting (unfrozen)...' % time.strftime(\"%H:%M:%S\"))\n",
    "                print (\"LSTM units %d\" % lstm_units)\n",
    "                print (\"LSTM reg_penalty %.8f\" % lstm_reg_penalty)\n",
    "                print (\"Sigmoid dropout %.4f\" %  dropout)\n",
    "                print (\"Sigmoid reg_penalty %.8f\" % sig_reg_penalty)\n",
    "\n",
    "                ##################################################################\n",
    "                # train end-to-end including embeddings until xval loss bottoms out\n",
    "                ##################################################################\n",
    "                \n",
    "                epochs = 10\n",
    "                for _ in range(epochs):\n",
    "                    fit = model.fit(X_train, y_train, validation_data=(X_xval, y_xval), epochs=1, batch_size=1024)\n",
    "                    # save loss\n",
    "                    train_loss = fit.history['loss'][-1]\n",
    "                    train_acc = fit.history['acc'][-1]\n",
    "                    xval_loss = fit.history['val_loss'][-1]\n",
    "                    xval_acc = fit.history['val_acc'][-1]\n",
    "                    xval_losses.append(xval_loss)\n",
    "                    models.append(copy.copy(model))\n",
    "\n",
    "                    bestloss_index = np.argmin(xval_losses)\n",
    "                    bestloss_value = xval_losses[bestloss_index]\n",
    "\n",
    "                    # break if loss rises by 10% from best\n",
    "                    if xval_loss / bestloss_value > 1.1:\n",
    "                        break\n",
    "                    \n",
    "                # keep model from epoch with best xval loss\n",
    "                print (\"%s Best Xval loss epoch %d, value %f\" % (time.strftime(\"%H:%M:%S\"), bestloss_index, bestloss_value))\n",
    "                model = models[bestloss_index]\n",
    "\n",
    "                print('%s Finished (unfrozen)...' % time.strftime(\"%H:%M:%S\"))\n",
    "                print (\"LSTM units %d\" % lstm_units)\n",
    "                print (\"LSTM reg_penalty %.8f\" % lstm_reg_penalty)\n",
    "                print (\"Sigmoid dropout %.4f\" %  dropout)\n",
    "                print (\"Sigmoid reg_penalty %.8f\" % sig_reg_penalty)                \n",
    "                \n",
    "                y_train_prob = model.predict(X_train)\n",
    "                \n",
    "                beta=(2.0/3.0) # penalize false positives more than false negatives\n",
    "                thresh, score = selectThreshold(y_train_prob, y_train, beta=beta)\n",
    "                y_train_pred = y_train_prob >= thresh\n",
    "\n",
    "                \n",
    "                print(\"%s Train Accuracy %.3f, Train F1 %.3f, f_score %.3f (beta %.3f)\" % \n",
    "                      (time.strftime(\"%H:%M:%S\"),\n",
    "                       sklearn.metrics.accuracy_score(y_train_pred, y_train), \n",
    "                       sklearn.metrics.f1_score(y_train_pred, y_train),\n",
    "                       score, beta))\n",
    "                \n",
    "                print(sklearn.metrics.confusion_matrix(y_train_pred, y_train))\n",
    "\n",
    "                y_xval_prob = model.predict(X_xval)\n",
    "                \n",
    "                thresh, score = selectThreshold(y_xval_prob, y_xval, beta=beta)\n",
    "                y_xval_pred = y_xval_prob >= thresh\n",
    "                \n",
    "                print(\"%s Xval Accuracy %.3f, Xval F1 %.3f, f_score %.3f (beta %.3f)\" % \n",
    "                      (time.strftime(\"%H:%M:%S\"),\n",
    "                       sklearn.metrics.accuracy_score(y_xval_pred, y_xval), \n",
    "                       sklearn.metrics.f1_score(y_xval_pred, y_xval),\n",
    "                       score, beta))\n",
    "                \n",
    "                confusion_matrix = sklearn.metrics.confusion_matrix(y_xval_pred, y_xval)\n",
    "                print(confusion_matrix)\n",
    "                false_positive = confusion_matrix[1][0]\n",
    "                false_negative = confusion_matrix[0][1]\n",
    "                true_positive = confusion_matrix[1][1]\n",
    "                raw_score = 1.0 * (true_positive - false_positive) / np.sum(confusion_matrix)\n",
    "                print (\"Raw score 2 %f\" % raw_score)\n",
    "\n",
    "                ##################################################################\n",
    "                # freeze embeddings, train LSTM until xval loss bottoms out\n",
    "                ##################################################################\n",
    "                elayer = model.layers[0]\n",
    "                \n",
    "                elayer.trainable = False\n",
    "                model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "                print(model.summary())\n",
    "\n",
    "                # Could also keep existing list of models in case further training makes it worse                \n",
    "                models = []\n",
    "                xval_losses = []\n",
    "                epochs = 20\n",
    "\n",
    "                print('%s Continuing (frozen)...' % time.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "                for _ in range(epochs):\n",
    "                    fit = model.fit(X_train, y_train, validation_data=(X_xval, y_xval), epochs=1, batch_size=1024)\n",
    "                    # save losses\n",
    "                    train_loss = fit.history['loss'][-1]\n",
    "                    train_acc = fit.history['acc'][-1]\n",
    "                    xval_loss = fit.history['val_loss'][-1]\n",
    "                    xval_acc = fit.history['val_acc'][-1]\n",
    "                    xval_losses.append(xval_loss)\n",
    "                    models.append(copy.copy(model))\n",
    "\n",
    "                    bestloss_index = np.argmin(xval_losses)\n",
    "                    bestloss_value = xval_losses[bestloss_index]\n",
    "    \n",
    "                    # break if loss rises by 10% from best\n",
    "                    if xval_loss / bestloss_value > 1.1:\n",
    "                        break\n",
    "                    \n",
    "                # keep model from epoch with best xval loss\n",
    "                print (\"%s Best Xval loss epoch %d, value %f\" % (time.strftime(\"%H:%M:%S\"), bestloss_index, bestloss_value))\n",
    "                # actually go back one from best... best is usually already overfitted with .9 train f1\n",
    "                if bestloss_index > 0:\n",
    "                    bestloss_index -= 1\n",
    "                model = models[bestloss_index]\n",
    "\n",
    "                print('%s Finished (frozen)...' % time.strftime(\"%H:%M:%S\"))\n",
    "                print (\"LSTM units %d\" % lstm_units)\n",
    "                print (\"LSTM reg_penalty %.8f\" % lstm_reg_penalty)\n",
    "                print (\"Sigmoid dropout %.4f\" %  dropout)\n",
    "                print (\"Sigmoid reg_penalty %.8f\" % sig_reg_penalty)                \n",
    "               \n",
    "                y_train_prob = model.predict(X_train)\n",
    "                \n",
    "                beta=(2.0/3.0) # penalize false positives more than false negatives\n",
    "                thresh, score = selectThreshold(y_train_prob, y_train, beta=beta)\n",
    "                y_train_pred = y_train_prob >= thresh\n",
    "                \n",
    "                print(\"%s Train Accuracy %.3f, Train F1 %.3f, f_score %.3f (beta %.3f)\" % \n",
    "                      (time.strftime(\"%H:%M:%S\"),\n",
    "                       sklearn.metrics.accuracy_score(y_train_pred, y_train),\n",
    "                       sklearn.metrics.f1_score(y_train_pred, y_train),\n",
    "                       score, beta))\n",
    "                \n",
    "                print(sklearn.metrics.confusion_matrix(y_train_pred, y_train))\n",
    "\n",
    "                y_xval_prob = model.predict(X_xval)\n",
    "                \n",
    "                thresh, score = selectThreshold(y_xval_prob, y_xval, beta=beta)\n",
    "                y_xval_pred = y_xval_prob >= thresh\n",
    "\n",
    "                print(\"%s Xval Accuracy %.3f, Xval F1 %.3f, f_score %.3f (beta %.3f)\" % \n",
    "                      (time.strftime(\"%H:%M:%S\"),\n",
    "                       sklearn.metrics.accuracy_score(y_xval_pred, y_xval), \n",
    "                       sklearn.metrics.f1_score(y_xval_pred, y_xval),\n",
    "                       score, beta))\n",
    "                \n",
    "                confusion_matrix = sklearn.metrics.confusion_matrix(y_xval_pred, y_xval)\n",
    "                print(confusion_matrix)\n",
    "                false_positive = confusion_matrix[1][0]\n",
    "                false_negative = confusion_matrix[0][1]\n",
    "                true_positive = confusion_matrix[1][1]\n",
    "\n",
    "                raw_score = 1.0 * (true_positive - false_positive) / np.sum(confusion_matrix)\n",
    "                print (\"Raw score 2 %f\" % raw_score)\n",
    "                \n",
    "                # save model to disk\n",
    "                print('%s Saving...' % time.strftime(\"%H:%M:%S\"))               \n",
    "                modelname = \"model_%d_%.6f_%.3f_%.6f\" % (lstm_units, lstm_reg_penalty, dropout, sig_reg_penalty)\n",
    "                model.save(\"%s.h5\" % modelname)\n",
    "                model.save_weights(\"%s_weights.h5\" % modelname)\n",
    "                with open(\"%s.json\" % modelname, \"wb\") as fjson:\n",
    "                    fjson.write(model.to_json()) \n",
    "                    \n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best model and evaluate in test set\n",
    "y_test_prob = model.predict(X_test)\n",
    "beta=(2.0/3.0) # penalize false positives more than false negatives\n",
    "\n",
    "y_test_pred = y_test_prob >= thresh\n",
    "print(\"Test Accuracy %.3f, Test F1 %.3f, f_score %.3f (beta %.3f)\" % \n",
    "                      (sklearn.metrics.accuracy_score(y_test_pred, y_test), \n",
    "                       sklearn.metrics.f1_score(y_test_pred, y_test),\n",
    "                       score, beta))\n",
    "                \n",
    "print(sklearn.metrics.confusion_matrix(y_test_pred, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
